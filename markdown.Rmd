---
title: "STAT685Project"
author: "Greg Carnovale"
date: "9/22/2019"
output: html_document
header-includes:
   - \usepackage{plyr}
   - \usepackage{dplyr}
   - \usepackage{ggplot2}
   - \usepackage{reshape2}
   - \usepackage{stringr}
   - \usepackage{MASS}
   - \usepackage{leaps}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Read in Data

Demographic data was only available for years 12 through 17
Previous Years 7th grad test score data was only available relative to 
the years 14 to 19. Algebra I is taken in 9th or 8th grade, so the test
results 2 years prior are most relevant. 
Because of these limitations the analysis was restricted to years 14 to 17. 
All columns also did match across years. When columns did not match or 
had too much missing data they were thrown out. 

```{r setup}
library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(stringr)
library(mice) # for missing values
library(MASS)
library(ISLR) 
library(leaps)
```


```{r plyr dplyr ggplot2 reshape2 stringr}

path <- "E:/STAT685/Data/"
dfy19ea1 <- read.csv(file=paste(path, 'dfy19ea1.dat',sep=''),na.strings=c("",'.',"NA"))
dfy18ea1 <- read.csv(file=paste(path, 'dfy18ea1.dat',sep=''),na.strings=c("",'.',"NA"))
dfy17ea1 <- read.csv(file=paste(path, 'dfy17ea1.dat',sep=''),na.strings=c("",'.',"NA"))
dfy16ea1 <- read.csv(file=paste(path, 'dfy16ea1.dat',sep=''),na.strings=c("",'.',"NA"))
dfy15ea1 <- read.csv(file=paste(path, 'dfy15ea1_dat.csv',sep=''),na.strings=c("",'.',"NA"))
dfy14ea1 <- read.csv(file=paste(path, 'dfy14ea1.dat',sep=''),na.strings=c("",'.',"NA"))
dfy13ea1 <- read.csv(file=paste(path, 'dfy13ea1.csv',sep=''),na.strings=c("",'.',"NA"))
dfy12ea1 <- read.csv(file=paste(path, 'dfy12ea1.csv',sep=''),na.strings=c("",'.',"NA"))

#read demographic data
dem18 <- read.csv(file=paste(path, 'district2018.dat',sep=''),na.strings=c("",'.',"NA"))
dem17 <- read.csv(file=paste(path, 'district2017.dat',sep=''),na.strings=c("",'.',"NA"))
dem16 <- read.csv(file=paste(path, 'district2016.dat',sep=''),na.strings=c("",'.',"NA"))
dem15 <- read.csv(file=paste(path, 'district2015.dat',sep=''),na.strings=c("",'.',"NA"))
dem14 <- read.csv(file=paste(path, 'district2014.dat',sep=''),na.strings=c("",'.',"NA"))
dem13 <- read.csv(file=paste(path, 'district2013.dat',sep=''),na.strings=c("",'.',"NA"))
dem12 <- read.csv(file=paste(path, 'district2012.dat',sep=''),na.strings=c("",'.',"NA"))

dfy17e7 <- read.csv(file=paste(path, 'dfy17e7.dat',sep=''),na.strings=c("",'.',"NA"))
dfy16e7 <- read.csv(file=paste(path, 'dfy16e7.dat',sep=''),na.strings=c("",'.',"NA"))
dfy15e7 <- read.csv(file=paste(path, 'dfy15e7_dat.csv',sep=''),na.strings=c("",'.',"NA"))
dfy14e7 <- read.csv(file=paste(path, 'dfy14e7.dat',sep=''),na.strings=c("",'.',"NA"))
dfy13e7 <- read.csv(file=paste(path, 'dfy13e7.csv',sep=''),na.strings=c("",'.',"NA"))
dfy12e7 <- read.csv(file=paste(path, 'dfy12e7.csv',sep=''),na.strings=c("",'.',"NA"))

#do not merge 2018 data, not enough time, too much rework
#dfy18ea1 <- merge(dfy18ea1, dem18, by='DISTRICT',all.x=TRUE)
dfy17ea1 <- merge(dfy17ea1, dem17, by='DISTRICT',all.x=TRUE)
dfy16ea1 <- merge(dfy16ea1, dem16, by='DISTRICT',all.x =TRUE)
dfy15ea1 <- merge(dfy15ea1, dem15, by='DISTRICT',all.x=TRUE)
dfy14ea1 <- merge(dfy14ea1, dem14, by='DISTRICT',all.x=TRUE)
dfy13ea1 <- merge(dfy13ea1, dem13, by='DISTRICT',all.x=TRUE)
dfy12ea1 <- merge(dfy12ea1, dem12, by='DISTRICT',all.x=TRUE)

names(dfy19ea1)[1:5] <- toupper(names(dfy19ea1[,1:5]))

dfy19ea1 <- merge(dfy19ea1,dfy17e7[,c('DISTRICT','m_all_rs','r_all_rs','w_all_rs')],by='DISTRICT')
dfy18ea1 <- merge(dfy18ea1,dfy16e7[,c('DISTRICT','m_all_rs','r_all_rs','w_all_rs')],by='DISTRICT')
dfy17ea1 <- merge(dfy17ea1,dfy15e7[,c('DISTRICT','m_all_rs','r_all_rs','w_all_rs')],by='DISTRICT')
dfy16ea1 <- merge(dfy16ea1,dfy14e7[,c('DISTRICT','m_all_rs','r_all_rs','w_all_rs')],by='DISTRICT')
dfy15ea1 <- merge(dfy15ea1,dfy13e7[,c('DISTRICT','m_all_rs','r_all_rs','w_all_rs')],by='DISTRICT')
dfy14ea1 <- merge(dfy14ea1,dfy12e7[,c('DISTRICT','m_all_rs','r_all_rs','w_all_rs')],by='DISTRICT')

all_years <- bind_rows(dfy19ea1,dfy18ea1,dfy17ea1,dfy16ea1,dfy15ea1,dfy14ea1,dfy13ea1,dfy12ea1)

```

### Missing Values
```{r}
miss_vals <- all_years %>%
  group_by(YEAR) %>%
  summarise_each(~sum(is.na(.)))
```

### Missing Results
By Year, we have a full account of each school that took the test. Demographic Data is
missing for all schools in years 12, 18 and 19. Seventh Grade Testing Information is missing 
from all schools in years 12 and 13 and for a few schols in the remaining years. When data is missing for a particluar school, that school will be dropped from the analysis. The response variable a1_all_rs is also missing from some years and will be dropped from that analysis. 
```{r}
miss_vals[,c('YEAR', 'DISTRICT','DISTNAME','m_all_rs','a1_all_rs')]

```


## Plot of the response by Year
The overall score is increasing year over year. This can also be seen in the gif map plot. The variance over years appears to be constant. The distribution of Test scores is right skewed. There are more large outliers than small outliers. Later, the response will be transformed using box cox to account for this skew.
```{r}
#violin plots
p <- ggplot(all_years, aes(x=as.factor(YEAR), y=a1_all_rs)) + 
  geom_violin()
p + ggtitle('Average Algebra 1 Score Over Years') + xlab('Testing Year') + ylab('Average Algebra 1 Score')
```

## Preliminary Plots
The initial plots give a good idea of the sign of certain predictors. Variable seleciton will be performed based upon predictors that contribute significantly to the model

### 7th Grade Test scores
```{r}
plt_mini <- all_years[all_years$YEAR >= 14,c('a1_all_rs','m_all_rs','r_all_rs','w_all_rs')]
colnames(plt_mini) <- c('Algebra 1 Exam Score', '7th Grade Math Score', '7th Grade Reading Score', '7th Grade Writing Score')
plot(plt_mini,main='7th Grade Test Scores Compared to 9th Grade Algebra I scores')
```

```{r eval = FALSE, echo = FALSE}
## plot vs select demographic data, only 17 and before are available
## taxable value per pupil,number of students per teacher,%economically disadvantaged
plot(all_years[all_years$YEAR <= 17,c('a1_all_rs','DPFVTOTK','DPSTKIDR','DPETECOP')])
#more demos
# total pop, number tested
plot(all_years[all_years$YEAR <= 17,c('a1_all_rs','DPETALLC','a1_all_d')])
#races
#simliar result to test score boxplots
plot(all_years[all_years$YEAR <= 17,c('a1_all_rs','DPETBLAP','DPETHISP','DPETWHIP'
                                      ,'DPETINDP','DPETASIP','DPETPCIP','DPETTWOP')])
#language, econ status, iq
#econ down # English learning no effect,outliers # special ed like e^-x
#bilingual maybe a little up, outliers
#vocational - downard trend, outliers
#gifted - upward trend
plot(all_years[all_years$YEAR <= 17,c('a1_all_rs','DPETECOP','DPETLEPP','DPETSPEP'
                                      ,'DPETBILP','DPETVOCP','DPETGIFP')])

# attendance, dropout, 4yr grad, 5 yr, 6 yr, grad cnt, 
# annual RHSP/DAP,FHSP-E etc.
#attendance outliers, but upward trend
# dropout outliers, but downard
# grad rate upward, but outliers
# grad cnt and RHSP no effect, decreasing variance
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DA0AT16R',
                  'DA0912DR16R',
                  'DAGC4X16R',
                  'DAGC5X15R',
                  'DAGC6X14R',
                  'DA0GR16N',
                  'DA0GS16N'
               )])
# STAAR VARIABLES
# Upward correlation for scores, but also correlated to each other
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DA00A001S17R',
                  'DA00AR01S17R',
                  'DA00AW01S17R',
                  'DA00AM01S17R',
                  'DA00AC01S17R',
                  'DA00AS01S17R',
                  'DB00A001S17R',
                  'DH00A001S17R',
                  'DW00A001S17R',
                  'DI00A001S17R',
                  'D300A001S17R',
                  'D400A001S17R',
                  'D200A001S17R',
                  'DE00A001S17R'
               )])

# college variables
# college at/above good
# SAT/ACT good corr., but also w/ each other
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DA0CT16R',
                  'DA0CC16R',
                  'DA0CSA16R',
                  'DA0CAA16R'
               )])
#teachers total
# no corr
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DPSATOFC',
                  'DPSTTOFC'
               )])

# staff
# no correlation
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DPSCTOFP',
                  'DPSSTOFP',
                  'DPSUTOFP',
                  'DPSTTOFP',
                  'DPSETOFP',
                  'DPSXTOFP',
                  'DPSAMIFP'
               )])

#salary
# upward trend
# last is teachers
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DPSCTOSA',
                  'DPSSTOSA',
                  'DPSUTOSA',
                  'DPSTTOSA'
               )])

#teacher info
#significant factors
# DPST05FP
# DPSTADFP
# DPSTURNR - teacher turnover rate
# DPSBLFP
# DPSTHIFP
# DPSTWHFP
# DPSTREFP
# DPSTSPFP
plot(all_years[all_years$YEAR <= 17
               ,c('a1_all_rs','DPSAKIDR',
                  'DPSTKIDR',
                  'DPST05FP',
                  'DPSTEXPA',
                  'DPSTADFP',
                  'DPSTURNR',
                  'DPSTBLFP',
                  'DPSTHIFP',
                  'DPSTWHFP',
                  'DPSTO2FP',
                  'DPSTREFP',
                  'DPSTSPFP',
                  'DPSTCOFP',
                  'DPSTBIFP',
                  'DPSTVOFP',
                  'DPSTGOFP'
               )])

#total
# mostly missing values
# no trends
foo <- all_years[all_years$YEAR <= 17
                 ,c('a1_all_rs','DPFVTOTK',
                    'DPFTADPR',
                    'DPFRAALLT',
                    'DPFRAALLK',
                    'DPFRASTAP',
                    'DZRVLOCP',
                    'DPFRAFEDP',
                    'DPFUNAB1T',
                    'DPFUNA4T',
                    'DPFEAALLT',
                    'DPFEAOPFT',
                    'DPFEAOPFK',
                    'DPFEAINST',
                    'DPFEAINSK'
                 )]
foo2 <- melt(foo, 'a1_all_rs')
p1 <- ggplot(foo2, aes(value, a1_all_rs)) +  geom_point() + facet_grid(.~variable)
plot(p1)

#revenue
# negative correlation with federal and state
# positive with local
foo <- all_years[all_years$YEAR <= 17
                 ,c('a1_all_rs','DPFRASTAP',
                    'DZRVLOCP',
                    'DPFRAFEDP'
                 )]
foo2 <- melt(foo, 'a1_all_rs')
p1 <- ggplot(foo2, aes(value, a1_all_rs)) +  geom_point() + facet_grid(.~variable)
plot(p1)


#expenditures pct 
# some missing values removed
# DPFPAREGP - regular 
# DPFPACOMP - accelerated
foo <- all_years[all_years$YEAR <= 17
                 ,c('a1_all_rs','DPFEAINSP',
                    'DZEXADMP',
                    'DZEXADSP',
                    'DZEXPLAP',
                    'DZEXOTHP',
                    'DPFPAREGP',
                    'DPFPASPEP',
                    'DPFPACOMP',
                    'DPFPABILP',
                    'DPFPAVOCP',
                    'DPFPAGIFP',
                    'DPFPAATHP',
                    'DPFPAHSAP',
                    'DPFPREKP',
                    'DPFPAOTHP'
                 )]
foo2 <- melt(foo, 'a1_all_rs')
p1 <- ggplot(foo2, aes(value, a1_all_rs)) +  geom_point() + facet_grid(.~variable)
plot(p1)
```


### boxplot by community type
```{r}
ggplot(data=all_years[all_years$YEAR <= 17,],aes(x=COMMTYPE,y=a1_all_rs))+geom_boxplot()+
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) + labs(title='Average Algebra 1 Score by Community Type')+xlab('Community Type')+ylab('Average Algebra 1 Score')
```

### District Size
We see here that as district size increases the variance also decreases. This motivates using district size as a weighting variable.
```{r}
ggplot(data=all_years[all_years$YEAR <= 17,],aes(x=DISTSIZE,y=a1_all_rs))+geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) + labs(title='Average Algebra 1 Score by District Size')+xlab('District Size')+ylab('Average Algebra 1 Score')
```


## reorder factor levels
```{r}
levels(all_years$DISTSIZE)
all_years$DISTSIZE_reorder <- factor(all_years$DISTSIZE,levels(all_years$DISTSIZE)[c(9,8,1,2,5,6,3,4,7)])
ggplot(data=all_years[all_years$YEAR <= 17,],aes(x=DISTSIZE_reorder,y=a1_all_rs))+geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) + labs(title='Average Algebra 1 Score by District Size')+xlab('District Size')+ylab('Average Algebra 1 Score')
plot(all_years$a1_all_d,all_years$a1_all_rs,main="District Size Vs Average Score")
```

## Add additional factor variable for community type
```{r}
levels(all_years$COMMTYPE)
new_comm_var<-model.matrix(~0+all_years$COMMTYPE)
colnames(new_comm_var)
gsub("-","",gsub(" ", "", levels(all_years$COMMTYPE),fixed=TRUE),fixed=TRUE)
all_years[!(is.na(all_years$COMMTYPE)),gsub("-","",gsub(" ", "", levels(all_years$COMMTYPE),fixed=TRUE),fixed=TRUE)] <- new_comm_var
```

## Create new variables
When a variable ends in a d it is a count. Dividing by the total number who took the test gives a percentage of each category that took the test. 
```{r}
all_years$PROPWLTHNUM<-as.numeric(gsub(",","",str_extract(all_years$PROPWLTH, "[0-9]{3},[0-9]{3}|[0-9]{1},[0-9]{3},[0-9]{3}")))
all_years$TAXRATENUM<-as.numeric(str_extract(all_years$TAXRATE, "[0-9]{1}.[0-9]{4}"))

#get all _d variables as a percentage
d_names <- grep('^(?!.*a1_all).+_d$',names(all_years),value=TRUE,perl=T)
var_names <- paste0(d_names,'_pct')
all_years[,var_names] <- all_years[,d_names]/all_years$a1_all_d
```

## find Variables with greater than 50% missing and exclude invalid years
Variables with greater than 50% missing cannot be imputed with the rest of the data. There are too many variables with >50% to give a full listing. A total of 2787 out of 3422 columns were removed for having > 50% missing data. Years 12, 13, 18 and 19 were excluded at this stage.
```{r}
#find missing percentage
miss_pct <- all_years %>%
  group_by(YEAR) %>%
  summarise_each(~sum(is.na(.))/n())
#find variables with less than 50% missing
val_cols<-colMeans(miss_pct[3:6,])<.5

val_years_n_vars <- all_years[all_years$YEAR > 13 & all_years$YEAR < 18
                              ,val_cols<-colMeans(miss_pct[3:6,])<.5]
ncol(all_years)
ncol(all_years) - ncol(val_years_n_vars)
```

## Remove variables that are not predictive
A number of variables were removed by pattern. The patterns match the following kinds of columns; average scale score when it is not the main predictor or one of the 7th grade scores, avg variables which contain average items correct in a reporting category, pct which includes percent items correct in a reporting category, nm variables which contain the number meeting performance in certain categories, rm which contains the percentage meeting performance in certain categories, some _d variables which are counts of variables which were earlier converted to percentages. Finally a1_all_docs_r was removed because it was found to have 0 variance later in modeling and produced singular matrices. Racial variables which were repeated in the test and demographic data were removed. 

```{r}
#remove variables that are not predictive
#remove rs variables,keep 7th grad variables though
#grep('^(?!.*m_all|r_all|w_all|a1_all).*_rs',names(val_years_n_vars),perl=T)
#remove avg
#grep('.+_avg_.+',names(val_years_n_vars))
#remove pct
#grep('.+_pct_.+',names(val_years_n_vars))
#remove _nm
#grep('.+_nm$',names(val_years_n_vars))
#remove _rm
#grep('.+_rm$',names(val_years_n_vars))
#remove some _d variables
#grep('^(?!.*a1_all).+_d$',names(val_years_n_vars),perl=T)
#find variables with variance equal to 0?
#grep('a1_all_docs_r',names(val_years_n_vars))


#racial and economic variables that are repeated in the numbers that took the test
racial_repeats <- c('DPETBLAP',
'DPETHISP',
'DPETWHIP',
'DPETINDP',
'DPETASIP',
'DPETPCIP',
'DPETTWOP'
)
#grep('DPET.+',names(val_years_n_vars),perl=T,value=T)
#missing categories
#grep('a1_.+v_d.+',names(val_years_n_vars),perl=T,value=T)
#no to a particular category
#grep('a1_.+n_d.+',names(val_years_n_vars),perl=T,value=T)
#yes to some categories with multiple letters
yes_cat <- 'a1_bily_d|a1_ecoy_d|a1_esly_d|a1_ti1y_d|a1_vocy_d|a1_esbiy_d_pct'
#grep(yes_cat,names(val_years_n_vars),value=T)
#categories not thought as predictive
no_pre <- 'Region.X|Region.Y|a1_all_docs_n|a1_all_abs_n|a1_all_oth_n|a1_all_abs_r|a1_all_oth_r|DZCAMPUS|Rural'
#grep(no_pre,names(val_years_n_vars),value=T)

bad_names_pos <- c(grep('^(?!.*m_all|r_all|w_all|a1_all).*_rs',names(val_years_n_vars),perl=T),
                   grep('.+_avg_.+',names(val_years_n_vars)),
                   grep('.+_pct_.+',names(val_years_n_vars)),
                   grep('.+_nm$',names(val_years_n_vars)),
                   grep('.+_rm$',names(val_years_n_vars)),
  grep('a1_.+v_d.+',names(val_years_n_vars),perl=T),           
  grep('DPET.+',names(val_years_n_vars),perl=T),
  grep('^(?!.*a1_all).+_d$',names(val_years_n_vars),perl=T),
  grep('a1_all_docs_r',names(val_years_n_vars)),
  grep('a1_.+n_d.+',names(val_years_n_vars),perl=T),
  grep(yes_cat,names(val_years_n_vars)),
  grep(no_pre,names(val_years_n_vars)))

#no to a particular category

#yes categories

#categories that do not make sense

#bad names removed
val_years_n_vars2 <- val_years_n_vars[,-bad_names_pos]

#additional variables to remove for logical reasons

#racial variables that are repeated in the numbers that took the test


```

## Remove missing a1_all_rs
49 missing values are removed at this step
```{r}
sum(is.na(val_years_n_vars2$a1_all_rs))
val_years_n_vars2 <- val_years_n_vars2[!is.na(val_years_n_vars2$a1_all_rs),]
```

## Impute missing values with their mean
Only imputing numeric values with their means. 
```{r}
n_miss_col = 0
n_miss_val = 0
#impute missing values
for(i in 1:ncol(val_years_n_vars2)){
  if (is.numeric(val_years_n_vars2[,i])){
    n_miss_col = n_miss_col + 1
    n_miss_val = n_miss_val + sum(is.na(val_years_n_vars2[,i]))
    val_years_n_vars2[is.na(val_years_n_vars2[,i]), i] <- mean(val_years_n_vars2[,i], na.rm = TRUE)
  }
}
n_miss_col
n_miss_val
```

## Restrict data to only the numeric columns
Restricting to only the numeric columns allows for principle components to be run.This removes 9 columns at this point. So finally we have 160 columns and 4334 observations to work with. 
```{r}
numeric_cols <- val_years_n_vars2[,sapply(val_years_n_vars2,is.numeric) ]
ncol(val_years_n_vars2)
ncol(numeric_cols)
ncol(val_years_n_vars2) - ncol(numeric_cols)
nrow(numeric_cols)
```

## split data into train and test
Set a reproducible seed
70/30 train test. 
60/20/20 train, test, validate
```{r}
smp_size <- floor(0.70 * nrow(numeric_cols))
set.seed(123)
#train_ind <- sample(seq_len(nrow(numeric_cols)), size = smp_size)
train_ind <- c(rep(1,smp_size),rep(0,nrow(numeric_cols)-smp_size))
train_ind <- sample(train_ind)
sum(train_ind)
numeric_cols$train_ind <- train_ind

spec = c(train = .6, test = .2, validate = .2)
g = sample(cut(
  seq(nrow(numeric_cols)), 
  nrow(numeric_cols)*cumsum(c(0,spec)),
  labels = names(spec)
))
frame_split = split(numeric_cols, g)

sapply(frame_split, nrow)/nrow(numeric_cols)

```

## split data for cross validation, 5 fold cross validation.
4336/(5*150) = 5.781 observations per column
4336/(10*150) = 2.89 observations per column
If we restrict the model to only have a maximum of so many predictors this ratio is not as pronounced. In any case, the limited number of observations pushes me towards 5 fold cross validation over 10 fold. 
```{r}
smp_size_k <- ceiling(0.70 * nrow(numeric_cols))
k_indices <- c(rep(1,smp_size_k),rep(2,smp_size_k),rep(3,smp_size_k),rep(4,smp_size_k),rep(5,smp_size_k))
k_indices <- sample(k_indices,size=nrow(numeric_cols))
numeric_cols$k_indices <- k_indices
```


## Run a prelminary model
This preliminary model identifies columns which cause the matrix to be singular. This could have been done at an earlier stage, but this is more like an error handling method. Some would say this is not a good idea?
variables to remove besides a1_all_d which will be used as weight
a1_sexv_d_pct
a1_ethv_d_pct
a1_eco9_d_pct
```{r}
#m0 <- lm(a1_all_rs ~ .,data=subset(numeric_cols, subset = numeric_cols$train_ind == 1, select=-c(train_ind,k_indices)))
m0 <- lm(a1_all_rs**-1.39 ~ ., data=frame_split$train)
sing_val_coef <- which(is.na(m0$coefficients))
#summary(m0)
sing_val_coef
```

### remove singular values from data
Twenty-One columns removed for causing singluar values
```{r}
library(knitr)
length(sing_val_coef)
to_rm <- names(sing_val_coef)[2:23]
#to_rm
if (length(sing_val_coef) > 1){
  numeric_cols_sing_rm <- numeric_cols[,-which(names(numeric_cols) %in% to_rm)]
} else {
  numeric_cols_sing_rm <- numeric_cols
}
#removed the singular columns before

#ncol(numeric_cols)-ncol(numeric_cols_sing_rm)
#kable(names(sing_val_coef))
```

## Run regression again to see if more are unestimatable
```{r}
m0.1 <- lm(a1_all_rs ~ .,data=subset(numeric_cols_sing_rm, subset = numeric_cols_sing_rm$train_ind == 1, select=-c(train_ind,k_indices)))
sing_val_coef.1 <- which(is.na(m0.1$coefficients))
#summary(m0.1)
sing_val_coef.1
```

## Run principle components
```{r}
#prin.comp.cols <- princomp(subset(numeric_cols_sing_rm, select=-c(train_ind,k_indices,a1_all_d)),cor=TRUE)
prin.comp.cols <- princomp(subset(frame_split$train, select=-c(a1_all_d,train_ind,k_indices,a1_all_rs)),cor=TRUE)
summary(prin.comp.cols)
plot(prin.comp.cols)

#cumsum()
```
```{r}
#plot first two principal components colored by a1_all_rs
#ggplot(prin.comp.cols$loadings[,1],prin.comp.cols$loadings[,1],colour=frame_split$train$a1_all_rs)
#biplot(prin.comp.cols)
#[1] "Charters"                   "IndependentTown"            "MajorSuburban"             
#[4] "MajorUrban"                 "NonmetropolitanFastGrowing" "NonmetropolitanStable"     
#[7] "OtherCentralCity"           "OtherCentralCitySuburban"   "Rural"  
prin_comp_frame <- data.frame(cbind(prin.comp.cols$scores[,1:2],algebra1score=frame_split$train$a1_all_rs ))
 # ,frame_split$train$Charters,frame_split$train$IndependentTown,frame_split$train$MajorSuburban
 # ,frame_split$train$MajorUrban,frame_split$train$NonmetropolitanFastGrowing,frame_split$train$NonmetropolitanStable
 # ,frame_split$train$OtherCentralCity,frame_split$train$OtherCentralCitySuburban,frame_split$train$Rural))
p <- ggplot(prin_comp_frame,aes(Comp.1, Comp.2))
p + geom_point(aes(colour = algebra1score)) + ggtitle('Principal Components Colored by Algebra Score') + labs(fill='Algebra 1 Score') + scale_colour_gradient(low='red',high='green')
```

```{r}
library(tibble)
#library(dplyr)
#left_join(rownames_to_column(prin_comp_frame), all_years$COMMTYPE, by = ("rowname" = "Symbol"))
res_prin_col <- merge(prin_comp_frame,all_years$COMMTYPE, all.x=TRUE, by='row.names')
ggplot(res_prin_col,aes(Comp.1, Comp.2)) + geom_point(aes(colour = y)) + labs(color="Community Type") + ggtitle('First Two Components Colored by Community Type')
#par(mfrow=c(3,3))
#for (x in levels(res_prin_col$y)){
  #print(x)
#  p <- ggplot(res_prin_col[res_prin_col$y==x,],aes(Comp.1, Comp.2)) + geom_point(aes(colour = y)) + ggtitle(paste("Community"),x) + xlim(-10,30) + ylim(-10,20) 
#  print(p)
#}
```

```{r}
print('Component 1')
sort(prin.comp.cols$loadings[,1])[1:5]
sort(prin.comp.cols$loadings[,1],decreasing=TRUE)[1:5]
print('Component 1')
sort(prin.comp.cols$loadings[,2])[1:5]
sort(prin.comp.cols$loadings[,2],decreasing=TRUE)[1:5]
print('Component 1')
sort(prin.comp.cols$loadings[,3])[1:5]
sort(prin.comp.cols$loadings[,3],decreasing=TRUE)[1:5]
print('Component 1')
sort(prin.comp.cols$loadings[,4])[1:5]
sort(prin.comp.cols$loadings[,4],decreasing=TRUE)[1:5]
```

##additional plots
```{r}
```

##transform the predictor using box-cox
```{r}
library(MASS)
library(ISLR) 
library(leaps)
#run 5 fold cross validation in selecting the box cox transformation
res_k_box_cox <- rep(0,5)
for (k in seq(1,5)){
k_out <- (numeric_cols_sing_rm$k_indices != k)
k_fold <- subset(numeric_cols_sing_rm,subset=k_out,select=a1_all_rs)
ones <- rep(1, length(k_fold$a1_all_rs))
a <- boxcox(lm(k_fold$a1_all_rs ~ ones),lambda = seq(-4, 2, 1/10))
max_x_for_y<- function(BC){
  with(BC, x[which.max(y)])
}
#plot(a)
res_k_box_cox[k]<-max_x_for_y(a)
}
res_k_box_cox 
shapiro.test(numeric_cols_sing_rm$a1_all_rs**-1.39)
qqnorm(numeric_cols_sing_rm$a1_all_rs,main="Untransformed Normal QQ")
qqnorm(numeric_cols_sing_rm$a1_all_rs**-1.39,main="Transformed Normal QQ")
```

```{r}
res_k_box_cox <- rep(0,5)
for (k in seq(1,5)){
k_out <- (numeric_cols_sing_rm$k_indices != k)
k_fold <- subset(numeric_cols_sing_rm,subset=k_out,select=a1_all_d)
ones <- rep(1, length(k_fold$a1_all_d))
a <- boxcox(lm(k_fold$a1_all_d ~ ones),lambda = seq(-4, 2, 1/10))
max_x_for_y<- function(BC){
  with(BC, x[which.max(y)])
}
#plot(a)
res_k_box_cox[k]<-max_x_for_y(a)
}
res_k_box_cox 
shapiro.test(numeric_cols_sing_rm$a1_all_d**-.181)
qqnorm(numeric_cols_sing_rm$a1_all_d,main="Untransformed Normal QQ")
qqnorm(numeric_cols_sing_rm$a1_all_rs**-.181,main="Transformed Normal QQ")
```

## Stepwise forward selection with cross validation
### without weights

```{r}
predict.regsubsets =function (object ,newdata ,id ,...){
  form=as.formula (object$call [[2]])
 mat=model.matrix (form ,newdata )
 coefi =coef(object ,id=id)
 xvars =names (coefi )
 mat[,xvars ]%*% coefi
 }
```

#things to remove
#add this to intial removes
```{r}
#to_remove = c(-REGION.x,-REGION.y,
 #                 -a1_all_docs_n,-a1_all_abs_n,-a1_all_oth_n,
  #                -a1_all_abs_r,-a1_all_oth_r)
```

#exclude region.y
```{r}
k=10
folds=sample (1:k,nrow(frame_split$train),replace =TRUE)
cv.errors.m1 =matrix (NA ,k,70, dimnames =list(NULL , paste (1:70) ))
for(j in 1:k){
  #k_out <- (numeric_cols_sing_rm$k_indices != j)
  #k_in <- (numeric_cols_sing_rm$k_indices == j)
  k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y))
  k_fold_test <- subset(frame_split$train,subset=(folds==j),select=c(-a1_all_d,-REGION.y))
  best.fit =regsubsets(a1_all_rs**-1.39∼.,data=k_fold,nvmax =70,method=c('seqrep'))
  for(i in 1:70) {
    pred=predict(best.fit ,k_fold_test, id=i)
    #print(c(i,j,mean(pred)))
    # 2384 in prediction is off
    cv.errors.m1 [j,i]=mean( (k_fold_test$a1_all_rs-pred**(-1/1.39))^2,na.rm = TRUE)
    }
}
```

Forward selection lowest MSE achieved with 30 variables at 19555.03
Forward and backward achieved the best at 35 variables with MSE 19521
foward and backware on train/test/val, with 26 variables with MSE 19491.63, but this was on less data
```{r}
mean.cv.errors.no_weights.all_vars =apply(cv.errors.m1 ,2, mean)
mean.cv.errors.no_weights.all_vars
plot(mean.cv.errors.no_weights.all_vars ,type='b')
which(mean.cv.errors.no_weights.all_vars==min(mean.cv.errors.no_weights.all_vars))
mean.cv.errors.no_weights.all_vars[which(mean.cv.errors.no_weights.all_vars==min(mean.cv.errors.no_weights.all_vars))]
```

### model chosen through cross validation has 38 variables
### build best model with 38 variables on all the data
```{r}
sub_model_build <- subset(frame_split$test,select=c(-a1_all_d,-REGION.x,-REGION.y))
reg.best=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build , nvmax =70,method=c('seqrep'))
coef(reg.best,26)
select_var <- names(coef(reg.best,26))[-1]
```

```{r}
#select_var
model.no_weights.all_vars <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build[,c(select_var,'a1_all_rs')])
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
```

### check diagnostic plots
```{r}
plot(model.no_weights.all_vars)
```

## see rowid outlier
Outlier 2384
Imagine International Acadamey of North Texas
```{r}
sub_model_build['2384',]
all_years['2384','DISTNAME']
all_years['5930','DISTNAME']
all_years['4835','DISTNAME']
```

### check for multicolinearity
Really Bad multicolinearity
```{r}
library(car)
vif(model.no_weights.all_vars)
```

### check that the prediction works for each variable chosen

### with weights

#exclude region.y
mess around with sqrt weights
```{r}
k=10
folds=sample (1:k,nrow(frame_split$train),replace =TRUE)
cv.errors.m2 =matrix (NA ,k,70, dimnames =list(NULL , paste (1:70) ))
for(j in 1:k){
  #k_out <- (numeric_cols_sing_rm$k_indices != j)
  #k_in <- (numeric_cols_sing_rm$k_indices == j)
  k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y))
  k_fold_test <- subset(frame_split$train,subset=(folds==j),select=c(-a1_all_d,-REGION.y))
  weights <- sqrt(frame_split$train[(folds!=j),c("a1_all_d")])
  best.fit =regsubsets(a1_all_rs**-1.39∼.,data=k_fold,nvmax =70,method=c('seqrep'),weights=weights)
  for(i in 1:70) {
    pred=predict(best.fit ,k_fold_test, id=i)
    #print(c(i,j,mean(pred)))
    # 2384 in prediction is off
    cv.errors.m2[j,i]=mean( (k_fold_test$a1_all_rs-pred**(-1/1.39))^2,na.rm = TRUE)
    }
}
```

40 variables, 21331.15 MSE
on train/test/val, 30 variable model mse 21386.9, but on less data and 10 fold val
sqrt weights, 42 is best, but graph shows around 21 is enough 19538 MSE
```{r}
mean.cv.errors.weights =apply(cv.errors.m2 ,2, mean)
mean.cv.errors.weights
plot(mean.cv.errors.weights ,type='b')
which(mean.cv.errors.weights==min(mean.cv.errors.weights))
mean.cv.errors.weights[which(mean.cv.errors.weights==min(mean.cv.errors.weights))]
```

### model chosen through cross validation has 38 variables
### build best model with 38 variables on all the data
variables better with sqrt weights
```{r}
sub_model_build <- subset(frame_split$test,select=c(-a1_all_d,-REGION.x,-REGION.y))
weights <- sqrt(frame_split$test[,c("a1_all_d")])
reg.best=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build , nvmax =70,method=c('seqrep'),weights=weights)
coef(reg.best,21)
select_var <- names(coef(reg.best,21))[-1]
```

```{r}
#select_var
model.weights.all_vars <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build[,c(select_var,'a1_all_rs')],weights=weights)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
```

### check diagnostic plots
No bad outliers
esp. with sqrt weights
```{r}
plot(model.weights.all_vars)
```

##check outliers
```{r}
all_years['2667','DISTNAME']
all_years['2384','DISTNAME']
all_years['6440','DISTNAME']
all_years['5989','DISTNAME']
```

### check for multicolinearity
Some bad multicolinearity, esp. with race. 
```{r}
m_weights<-vif(model.weights.all_vars)
m_weights
which(m_weights>7)
co_lin_vars<-names(which(m_weights>7))
paste(co_lin_vars,sep='-,',collapse = ',-')
```

### remove additional variables
#things to remove
#add this to intial removes
```{r}
#remove double test scores, remove double ethnicity
#to_remove2 = c(-r_all_rs,-w_all_rs,-DZCAMPUS,-DPETBLAP,-DPETHISP,-DPETWHIP,-DPETINDP,
#-DPETASIP,-DPETPCIP,-DPETTWOP,-DPETBILP,-DPSTTOFC,-DPFEAOPFT,-DPFEAINST
#)

#variables in third round
#DPFEAALLT, DPFEAINST
```

Using forward selection
It gave more interpretable estimates
trying with sqrt weights and some multicolinear removed
```{r}
k=10
folds=sample (1:k,nrow(frame_split$train),replace =TRUE)
cv.errors.m3=matrix (NA ,k,70, dimnames =list(NULL , paste (1:70) ))
for(j in 1:k){
  #k_out <- (numeric_cols_sing_rm$k_indices != j)
  #k_in <- (numeric_cols_sing_rm$k_indices == j)
  #k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y))
  k_fold_test <- subset(frame_split$train,subset=(folds==j),select=c(-a1_all_d,-REGION.y))
  #k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPSATOFC,-DPSTTOFC,-DPSCTOFP,-DPSSTOFP,-DPSUTOFP,-DPSTTOFP,-DPSETOFP,-DPSXTOFP,-DPSAMIFP,-DPSAKIDR,-DPSTKIDR,-DPST05FP,-DPSTEXPA,-DPSTBLFP,-DPSTHIFP,-DPSTWHFP,-DPSTO2FP,-DPSTREFP,-DPSTSPFP,-DPSTCOFP,-DPSTBIFP,-DPSTVOFP,-DPSTGOFP,-DPFRAALLT,-DPFRASTAP,-DZRVLOCP,-DPFRAFEDP,-DPFEAALLT, -DPFEAINST))
  k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST,-DPSATOFC,-train_ind))
  #k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
  
  #k_fold_test <- subset(numeric_cols_sing_rm,subset=k_in,select=c(-k_indices,-train_ind,-REGION.y))
  weights <- sqrt(frame_split$train[(folds!=j),c("a1_all_d")])
  best.fit =regsubsets(a1_all_rs**-1.39∼.,data=k_fold,nvmax =70,method=c('forward'),weights=weights)
  for(i in 1:70) {
    pred=predict(best.fit ,k_fold_test, id=i)
    #print(c(i,j,mean(pred)))
    # 2384 in prediction is off
    cv.errors.m3[j,i]=mean( (k_fold_test$a1_all_rs-pred**(-1/1.39))^2,na.rm = TRUE)
    }
}
```

#MSE 
Foward 18, 22043 MSE. The diagnostic plot shows a strong outlier.
Sequential 21, 22186
Forward 10, 21181.48
Sequential 10 21424.59
Foward w/ sqrt weights 25, 19451.44
Sequential w/ sqrt weights 25 (28), 19670.72
```{r}
mean.cv.errors.limited.weights =apply(cv.errors.m3 ,2, mean)
mean.cv.errors.limited.weights
plot(mean.cv.errors.limited.weights ,type='b')
which(mean.cv.errors.limited.weights==min(mean.cv.errors.limited.weights))
mean.cv.errors.limited.weights[which(mean.cv.errors.limited.weights==min(mean.cv.errors.limited.weights))]
```

Removed Extra econ variables for high vif
trying with sqrt weights
Minimum MSE is achieved at 30, but 20 looks just as good
```{r}
#sub_model_build <- subset(frame_split$test,select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPSATOFC,-DPSTTOFC,-DPSCTOFP,-DPSSTOFP,-DPSUTOFP,-DPSTTOFP,-DPSETOFP,-DPSXTOFP,-DPSAMIFP,-DPSAKIDR,-DPSTKIDR,-DPST05FP,-DPSTEXPA,-DPSTBLFP,-DPSTHIFP,-DPSTWHFP,-DPSTO2FP,-DPSTREFP,-DPSTSPFP,-DPSTCOFP,-DPSTBIFP,-DPSTVOFP,-DPSTGOFP,-DPFRAALLT,-DPFRASTAP,-DZRVLOCP,-DPFRAFEDP,-DPFEAALLT, -DPFEAINST))
sub_model_build.train <- subset(frame_split$train,select=c(-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST,-DPSATOFC,-train_ind))
weights.train <- sqrt(frame_split$train[,c("a1_all_d")])
sub_model_build.test <- subset(frame_split$test,select=c(-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST,-DPSATOFC,-train_ind))
weights.test <- sqrt(frame_split$test[,c("a1_all_d")])
reg.best.train=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build.train, nvmax =70,method=c('forward'),weights=weights.train)
coef(reg.best.train,37)
start_coef <- coef(reg.best.train,37)
select_var.weight.limit.sq <- names(coef(reg.best.train,42))[-1]
```

```{r}
#select_var
m3.limited.weights <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build.train[,c(select_var.weight.limit.sq ,'a1_all_rs')],weights=weights.train)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)

summary(m3.limited.weights)
m3.limited.weights.test <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build.test[,c(select_var.weight.limit.sq ,'a1_all_rs')],weights=weights.test)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)

summary(m3.limited.weights.test)
```
## Variable Interpretation
```{r}
transform_coef <- function(x){
  -sign(x)*abs(x)**(1/-1.39)
}
t(data.frame(lapply(coef(m3.limited.weights,20),transform_coef)))
```

## check the limited variable model without weights and compare MSE.


### check diagnostic plots
Some far outliers, 

```{r}
plot(m3.limited.weights)
plot(m3.limited.weights.test)
```

```{r}
pred.train.w_sq <- predict(m3.limited.weights, frame_split$train, weights=frame_split$train$a1_all_d)
pred.test.w_sq <- predict(m3.limited.weights, frame_split$test, weights=frame_split$test$a1_all_d)
pred.val.w_sq <- predict(m3.limited.weights, frame_split$validate, weights=frame_split$validate$a1_all_d)
plot(frame_split$train$a1_all_rs,pred.train.w_sq**(-1/1.39),main='Actual vs Predicted',xlab='Acutal Train',ylab='Predicted Train')
plot(frame_split$test$a1_all_rs,pred.test.w_sq**(-1/1.39),main='Actual vs Predicted',xlab='Acutal Test',ylab='Predicted Test')
plot(frame_split$validate$a1_all_rs,pred.val.w_sq**(-1/1.39),main='Actual vs Predicted',xlab='Acutal Validation',ylab='Predicted Validation')
```

##check one outlier
This is Houston. It is humongous
```{r}
all_years['2667','DISTNAME']
all_years['3486','DISTNAME']
all_years['5641','DISTNAME']
all_years['2641','DISTNAME']
all_years['4642','DISTNAME']
```

### check for multicolinearity
Restricted to forward selection. In stepwise there was bad multicolinearity.
This model confirms many of our pre-existing assumptions. It is good from that perspective.
```{r}
vif(m3.limited.weights)
```

### make plots to show the effect of each variable
```{r}
for (var_name in names(coef(m3.limited.weights)[2:14])){
  graph_path <- "E:/STAT685/Graphs/"
  #png(paste0(""))
  pp <- plot(numeric_cols_sing_rm[,"a1_all_rs"],numeric_cols_sing_rm[,var_name],
       main=paste("Average Scale Score vs.", var_name))
  png(paste0(graph_path,"resp",var_name,".png"), width=648, height=432)
  print(pp)
  dev.off()
}
```

```{r}
plot(numeric_cols_sing_rm$a1_ethb_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percentage Black Tested vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage Black Tested")
plot(numeric_cols_sing_rm$DPSTURNR,numeric_cols_sing_rm$a1_all_rs,main="Teacher Turnover Rate vs. Average Scale Score",ylab="Average Scale Score",xlab="Teacher Turnover Rate")
plot(numeric_cols_sing_rm$a1_etha_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percent Asian Tested vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage Asian Tested")
plot(numeric_cols_sing_rm$a1_lepf_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percentage Non-LEP (First Year Monitored) Students \n vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage Non-LEP (First Year Monitored) Students Tested")
plot(numeric_cols_sing_rm$a1_gify_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percentage Gifted Tested vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage Gifted Tested")
plot(numeric_cols_sing_rm$a1_atry_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percentage At Risk Tested vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage At Risk Tested")
plot(numeric_cols_sing_rm$a1_spey_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percentage Special Education Tested vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage Special Education Tested")
plot(numeric_cols_sing_rm$a1_eco1_d_pct,numeric_cols_sing_rm$a1_all_rs,main="Percentage Free Meal Students Tested vs. Average Scale Score",ylab="Average Scale Score",xlab="Percentage Free Meal Students Tested")
```

```{r}
#variables in third round
#additiona variables that duplicate information
#to_remove3 = c(-DPETALLC,-DPETECOP,-DPETLEPP,-DPSATOFC,-DPSAMIFP,)
```

## Run without sqrt weights
Using forward selection
It gave more interpretable estimates
trying with sqrt weights and some multicolinear removed
```{r}
k=10
folds=sample (1:k,nrow(frame_split$train),replace =TRUE)
cv.errors.m3.nsq =matrix (NA ,k,70, dimnames =list(NULL , paste (1:70) ))
for(j in 1:k){
  #k_out <- (numeric_cols_sing_rm$k_indices != j)
  #k_in <- (numeric_cols_sing_rm$k_indices == j)
  k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
  k_fold_test <- subset(frame_split$train,subset=(folds==j),select=c(-a1_all_d,-REGION.y))
  #k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPSATOFC,-DPSTTOFC,-DPSCTOFP,-DPSSTOFP,-DPSUTOFP,-DPSTTOFP,-DPSETOFP,-DPSXTOFP,-DPSAMIFP,-DPSAKIDR,-DPSTKIDR,-DPST05FP,-DPSTEXPA,-DPSTBLFP,-DPSTHIFP,-DPSTWHFP,-DPSTO2FP,-DPSTREFP,-DPSTSPFP,-DPSTCOFP,-DPSTBIFP,-DPSTVOFP,-DPSTGOFP,-DPFRAALLT,-DPFRASTAP,-DZRVLOCP,-DPFRAFEDP,-DPFEAALLT, -DPFEAINST))
  #k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
  #k_fold_resp <- frame_split$train$a1_all_rs[folds!=j]
  #k_fold_test <- subset(numeric_cols_sing_rm,subset=k_in,select=c(-k_indices,-train_ind,-REGION.y))
  weights <- frame_split$train[(folds!=j),c("a1_all_d")]
  best.fit =regsubsets(a1_all_rs**-1.39∼.,data=k_fold,nvmax =70,method=c('forward'),weights=weights)
  for(i in 1:70) {
    pred=predict(best.fit ,k_fold_test, id=i)
    #print(c(i,j,mean(pred)))
    # 2384 in prediction is off
    cv.errors.m3.nsq [j,i]=mean( (k_fold_test$a1_all_rs-pred**(-1/1.39))^2,na.rm = TRUE)
    }
}
```
#MSE 
Foward 18, 22043 MSE. The diagnostic plot shows a strong outlier.
Sequential 21, 22186
Forward 10, 21181.48
Sequential 10 21424.59
Foward w/ sqrt weights 25, 19451.44
Sequential w/ sqrt weights 25 (28), 19670.72
Foward 63 w/o sqrt weights, but good at 12
```{r}
mean.cv.errors.limited.weights.nsq =apply(cv.errors.m3.nsq ,2, mean)
mean.cv.errors.limited.weights.nsq
plot(mean.cv.errors.limited.weights.nsq ,type='b')
which(mean.cv.errors.limited.weights.nsq==min(mean.cv.errors.limited.weights.nsq))
mean.cv.errors.limited.weights.nsq[which(mean.cv.errors.limited.weights.nsq==min(mean.cv.errors.limited.weights.nsq))]
```

Removed Extra econ variables for high vif
trying with sqrt weights
```{r}
#sub_model_build <- subset(frame_split$test,select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPSATOFC,-DPSTTOFC,-DPSCTOFP,-DPSSTOFP,-DPSUTOFP,-DPSTTOFP,-DPSETOFP,-DPSXTOFP,-DPSAMIFP,-DPSAKIDR,-DPSTKIDR,-DPST05FP,-DPSTEXPA,-DPSTBLFP,-DPSTHIFP,-DPSTWHFP,-DPSTO2FP,-DPSTREFP,-DPSTSPFP,-DPSTCOFP,-DPSTBIFP,-DPSTVOFP,-DPSTGOFP,-DPFRAALLT,-DPFRASTAP,-DZRVLOCP,-DPFRAFEDP,-DPFEAALLT, -DPFEAINST))
sub_model_build <- subset(frame_split$train,select=c(-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
weights <- frame_split$train[,c("a1_all_d")]
reg.best=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build , nvmax =70,method=c('forward'),weights=weights)
coef(reg.best,20)
start_coef.weight.limit <- coef(reg.best,20)
select_var.weight.limit <- names(coef(reg.best,20))[-1]
```

```{r}
#select_var
m3.limited.weights.nsq <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build[,c(select_var.weight.limit,'a1_all_rs')],weights=weights)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
summary(m3.limited.weights.nsq)
```

## check the limited variable model without weights and compare MSE.


### check diagnostic plots
Some far outliers, 

```{r}
plot(m3.limited.weights.nsq)
```

##vif
```{r}
vif(m3.limited.weights.nsq)
```

##check one outlier
This is Houston. It is humongous
```{r}
all_years['2667','DISTNAME']
all_years['3486','DISTNAME']
all_years['5641','DISTNAME']
all_years['2641','DISTNAME']
all_years['2392','DISTNAME']
```

## Check the limited variable model without weights and compare
```{r}
k=10
folds=sample (1:k,nrow(frame_split$train),replace =TRUE)
cv.errors.m4 =matrix (NA ,k,70, dimnames =list(NULL , paste (1:70) ))
for(j in 1:k){
  #k_out <- (numeric_cols_sing_rm$k_indices != j)
  #k_in <- (numeric_cols_sing_rm$k_indices == j)
  #k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y))
  k_fold_test <- subset(frame_split$train,subset=(folds==j),select=c(-a1_all_d,-REGION.y))
  k_fold <- subset(frame_split$train,subset=(folds!=j),select=c(-a1_all_d,-REGION.x,-REGION.y,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
  #k_fold_test <- subset(numeric_cols_sing_rm,subset=k_in,select=c(-k_indices,-train_ind,-REGION.y))
  #weights <- frame_split$train[(folds!=j),c("a1_all_d")]
  best.fit =regsubsets(a1_all_rs**-1.39∼.,data=k_fold,nvmax =70,method=c('seqrep'))
  for(i in 1:70) {
    pred=predict(best.fit ,k_fold_test, id=i)
    #print(c(i,j,mean(pred)))
    # 2384 in prediction is off
    cv.errors.m4 [j,i]=mean( (k_fold_test$a1_all_rs-pred**(-1/1.39))^2,na.rm = TRUE)
    }
}
```

Lowest was at 26, 19763.
Lowest was at 17, 19625.18
```{r}
mean.cv.errors.noweights.limited =apply(cv.errors.m4 ,2, mean)
mean.cv.errors.noweights.limited
plot(mean.cv.errors.noweights.limited ,type='b')
which(mean.cv.errors.noweights.limited==min(mean.cv.errors.noweights.limited))
mean.cv.errors.noweights.limited[which(mean.cv.errors.noweights.limited==min(mean.cv.errors.noweights.limited))]
```



## without weights 32 variable model selected, w/ limited data
try taking the log of the weights to reduce their power over houston
log not powerful enough what about sqrt
or could box cox also work here?
sqrt kinda works
```{r}
sub_model_build <- subset(frame_split$train,select=c(-a1_all_d,-REGION.x,-REGION.y,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))

weights <- sqrt(frame_split$test[,c("a1_all_d")])
reg.best=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build , nvmax =70,method=c('seqrep'))
coef(reg.best,22)
select_var <- names(coef(reg.best,22))[-1]
```

Plopping in the weights takes care of the residuals but causes outliers
```{r}
#select_var
m4.noweights.limited <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build[,c(select_var,'a1_all_rs')])
m4.coef_names <- names(coef(m4.noweights.limited))[-1]
m4.coef <- coef(m4.noweights.limited)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
```

## check the limited variable model without weights and compare MSE.


### check diagnostic plots
Increasing variance, not good
But if I plop in the weights it looks good
```{r}
plot(m4.noweights.limited)
```

## outliers

### check for multicolinearity

```{r}
vif(m4.noweights.limited)
```

#box cox on all variables
boxcox on the weighted model with few parameters
Box cox on all variables yielded an interval which contains 1 which suggests that only transformation of the the target is required. 
```{r}
sub_model_build <- subset(frame_split$train,select=c(-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
weights <- sqrt(frame_split$train[,c("a1_all_d")])
reg.best=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build , nvmax =70,method=c('forward'),weights=weights)
#coef(reg.best,20)
select_var.weight.limit.sq <- names(coef(reg.best,20))[-1]
m3.bc <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build[,c(select_var.weight.limit.sq ,'a1_all_rs')],weights=weights)
bc_all <- boxcox(m3.bc, lambda = seq(-2, 2, 1/10))
```


#compare MSE from the three models
Comparison of MSE from the three techniques of choosing a model.
This is not coming out how I like.
```{r}

plot_mse <- data.frame(cbind(seq(1,70),mean.cv.errors.no_weights.all_vars,mean.cv.errors.weights,
                                 mean.cv.errors.limited.weights, mean.cv.errors.noweights.limited))
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ggplot(plot_mse) +
  geom_line(aes(x=V1,y=mean.cv.errors.no_weights.all_vars,colour="No Weights")) +
  geom_line(aes(x=V1,y=mean.cv.errors.weights,colour='Weights')) +
  geom_line(aes(x=V1,y=mean.cv.errors.limited.weights,colour='Weights + Limited Vars')) +
  geom_line(aes(x=V1,y=mean.cv.errors.noweights.limited,colour='No Weights + Limited Vars')) +
  geom_line(aes(x=V1,y=mean.cv.errors.limited.weights.nsq,colour='Weights + Limited Vars + No Sqrt Weights')) +
  ggtitle("Mean Cross Validation Error with 10 Folds") + scale_colour_manual(values=cbPalette) + xlab('Number of Variables')+ylab('Mean Square Error')
```

Compare diagnostics from the different models
```{r}

```

Compare MSE on the test sets
and on the validation set
Also do MAE?
```{r}
  res.pred = rep(0,5)
  pred1=predict(model.no_weights.all_vars ,frame_split$validate)
  pred2=predict(model.weights.all_vars ,frame_split$validate)
  pred3=predict(m3.limited.weights ,frame_split$validate)
  pred4=predict(m4.noweights.limited ,frame_split$validate)
  pred.nsq=predict(m3.limited.weights.nsq ,frame_split$validate)
  mean( (frame_split$validate$a1_all_rs-pred1**(-1/1.39))^2,na.rm = TRUE)
  mean( (frame_split$validate$a1_all_rs-pred2**(-1/1.39))^2,na.rm = TRUE)
  mean( (frame_split$validate$a1_all_rs-pred3**(-1/1.39))^2,na.rm = TRUE)
  mean( (frame_split$validate$a1_all_rs-pred4**(-1/1.39))^2,na.rm = TRUE)
  mean( (frame_split$validate$a1_all_rs-pred.nsq**(-1/1.39))^2,na.rm = TRUE)
  mean( abs(frame_split$validate$a1_all_rs-pred1**(-1/1.39)),na.rm = TRUE)
  mean( abs(frame_split$validate$a1_all_rs-pred2**(-1/1.39)),na.rm = TRUE)
  mean( abs(frame_split$validate$a1_all_rs-pred3**(-1/1.39)),na.rm = TRUE)
  mean( abs(frame_split$validate$a1_all_rs-pred4**(-1/1.39)),na.rm = TRUE)
  mean( abs(frame_split$validate$a1_all_rs-pred.nsq**(-1/1.39)),na.rm = TRUE)
```

## check correlation among school districts
```{r}
pred_all_m1 <- predict(m3.limited.weights ,numeric_cols_sing_rm)
resid_all_m1 <- numeric_cols_sing_rm$a1_all_rs**(-1/1.39)-pred_all_m1
res_all_m1 <- merge(resid_all_m1,all_years[,c('YEAR','DISTRICT')], all.x=TRUE, by='row.names')
res_all_m1_14_15 <- merge(res_all_m1[res_all_m1$YEAR==14,],res_all_m1[res_all_m1$YEAR==15,],by='DISTRICT')
res_all_m1_14_16 <- merge(res_all_m1_14_15,res_all_m1[res_all_m1$YEAR==16,],by='DISTRICT')
res_all_m1_14_17 <- merge(res_all_m1_14_16,res_all_m1[res_all_m1$YEAR==17,],by='DISTRICT')
resid_14_17 <- res_all_m1_14_17[,c(3,6,9,12)]
colnames(resid_14_17) <- c('2014','2015','2016','2017')
cor(resid_14_17)
plot(resid_14_17)
plot(res_all_m1_14_15$x.x, res_all_m1_14_15$x.y)
cor(res_all_m1_14_15$x.x, res_all_m1_14_15$x.y,method='spearman')
#var(resid_all_m1)

plot(res_all_m1_14_16$x.x, res_all_m1_14_16$x.y)
cor(res_all_m1_14_16$x.x, res_all_m1_14_16$x.y,method='spearman')

plot(res_all_m1_14_17$x.x, res_all_m1_14_17$x.y)
cor(res_all_m1_14_17$x.x, res_all_m1_14_17$x.y,method='spearman')
```
##check correlation in other models
```{r}
pred_all_m1 <- predict(model.weights.all_vars ,numeric_cols_sing_rm)
resid_all_m1 <- numeric_cols_sing_rm$a1_all_rs-pred_all_m1**(-1/1.39)
res_all_m1 <- merge(resid_all_m1,all_years[,c('YEAR','DISTRICT')], all.x=TRUE, by='row.names')
res_all_m1_14_15 <- merge(res_all_m1[res_all_m1$YEAR==14,],res_all_m1[res_all_m1$YEAR==15,],by='DISTRICT')
colnames(res_all_m1_14_15)
plot(res_all_m1_14_15$x.x, res_all_m1_14_15$x.y)
cor(res_all_m1_14_15$x.x, res_all_m1_14_15$x.y)
```

## lasso model
## should try elastic net
Trying without weights first. Run on train test split
Lasso did not do great, had the target in the model
```{r}
library(glmnet)
#cv.glmnet
set.seed(1011)
X <- as.matrix(subset(frame_split$train ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
y <- frame_split$train$a1_all_rs**-1.39
#without weights
elastic_net <- cv.glmnet(X,y,nfolds = 10)
#print(elastic_net)
summary(elastic_net)
plot(elastic_net)
coef(elastic_net)
coef(elastic_net, s='lambda.min')
bestlam =elastic_net$lambda.min
```
Test model
```{r}
X_test <- as.matrix(subset(frame_split$test ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
#res.lasso <- predict(elastic_net,X_test,type ="coefficients",s=bestlam)
#res.lasso

pred.lasso.test = predict(elastic_net, newx = X_test, s=bestlam)
mean( (frame_split$test$a1_all_rs-pred.lasso.test**(-1/1.39))^2)
mean( abs(frame_split$test$a1_all_rs-pred.lasso.test**(-1/1.39)))

bestlam
new.xx <- as.matrix(subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
pred5 = predict(elastic_net, newx = new.xx, s=bestlam)
mean( (frame_split$validate$a1_all_rs-pred5**(-1/1.39))^2, na.rm=TRUE)
mean( abs(frame_split$validate$a1_all_rs-pred5**(-1/1.39)), na.rm=TRUE)
```

##box cox on the weights?


##model with weights in lasso
sqrt weights worked well with the lasso
```{r}
set.seed(1011)
X <- as.matrix(subset(frame_split$train ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
y <- frame_split$train$a1_all_rs**-1.39
#weights.train <- sqrt(frame_split$train$a1_all_d)
weights.train <- frame_split$train$a1_all_d**-.1818
#without weights
elastic_net <- cv.glmnet(X,y,nfolds = 10,weights = weights.train)
#print(elastic_net)
summary(elastic_net)
plot(elastic_net)
coef(elastic_net)
coef(elastic_net, s='lambda.min')
bestlam.weights =elastic_net$lambda.min
pred.lasso.train.weights <- predict(elastic_net, newx = X, s=bestlam, weights=weights.train)

X_test <- as.matrix(subset(frame_split$test ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
weights.test <- sqrt(frame_split$test$a1_all_d)
#weights.test <- frame_split$test$a1_all_d**-.1818
#res.lasso <- predict(elastic_net,X_test,type ="coefficients",s=bestlam)
#res.lasso

pred.lasso.test.weights = predict(elastic_net, newx = X_test, s=bestlam, weights=weights.test)
mean( (frame_split$test$a1_all_rs-pred.lasso.test.weights**(-1/1.39))^2)
mean( abs(frame_split$test$a1_all_rs-pred.lasso.test.weights**(-1/1.39)))

bestlam
new.xx <- as.matrix(subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
weights.val <- sqrt(frame_split$validate$a1_all_d)
#weights.val <- frame_split$validate$a1_all_d**-.1818
pred.lasso.validate.weights = predict(elastic_net, newx = new.xx, s=bestlam.weights,weights=weights.val)
mean( (frame_split$validate$a1_all_rs-pred.lasso.validate.weights**(-1/1.39))^2,na.rm = TRUE)
mean( abs(frame_split$validate$a1_all_rs-pred.lasso.validate.weights**(-1/1.39)),na.rm = TRUE)
```

#predicted vs actual
```{r}
plot(frame_split$train$a1_all_rs,pred.lasso.train.weights**(-1/1.39),main='Actual vs Predicted',xlab='Acutal Train',ylab='Predicted Train')
plot(frame_split$test$a1_all_rs,pred.lasso.test.weights**(-1/1.39),main='Actual vs Predicted',xlab='Acutal Test',ylab='Predicted Test')
plot(frame_split$validate$a1_all_rs,pred.lasso.validate.weights**(-1/1.39),main='Actual vs Predicted',xlab='Acutal Validation',ylab='Predicted Validation')
```

## can I test multicolinearity with lasso
no, does not work with the model, will need to test things myself
```{r}
#vif(elastic_net)
```

## Coefficients in Original Scale
```{r}
transform_coef <- function(x){
  -sign(x)*abs(x)**(1/-1.39)
}
#rownames(coef(elastic_net, s='lambda.min'))
x <- data.frame(rownames(coef(elastic_net, s='lambda.min')),sapply(coef(elastic_net, s='lambda.min'),transform_coef))
write.csv(x, file="E:/STAT685/Report/lasso_coef.csv")
```

#plot predicted vs actual
```{r}
  plot(frame_split$validate$a1_all_rs,pred3**(-1/1.39))
  plot(frame_split$validate$a1_all_rs,pred5**(-1/1.39))
  plot(frame_split$test$a1_all_rs,pred.lasso.test**(-1/1.39))
```

```{r}
outlier=which((frame_split$validate$a1_all_rs-pred5**(-1/1.39))==max(frame_split$validate$a1_all_rs-pred5**(-1/1.39)))
frame_split$validate[outlier,]
outlier=which((frame_split$test$a1_all_rs-pred5**(-1/1.39))==max(frame_split$test$a1_all_rs-pred5**(-1/1.39)))
frame_split$test[outlier,]
```
Bpth of these are 8th grade schools, so they are taking the test ahead of time. Which my explain the differences in results.
```{r}
all_years['6144',]
all_years['3927',]
```

##plot predictors vs the predictions?
```{r}
#pred.lasso.train.weights
#pred.lasso.test.weights
#pred.lasso.validate.weights
plot(frame_split$train$a1_all_rs,pred.lasso.train.weights**(1/-1.39))
plot(frame_split$test$a1_all_rs,pred.lasso.test.weights**(1/-1.39))
plot(frame_split$validate$a1_all_rs,pred.lasso.validate.weights**(1/-1.39))
```

##plot error/residuals vs predictors
```{r}
```

##plot years residuals
```{r, eval=FALSE}
new.xx <- as.matrix(numeric_cols_sing_rm[,rownames(coef(elastic_net))[2:104]])
weights.val <- sqrt(numeric_cols_sing_rm$a1_all_d)
#weights.val <- frame_split$validate$a1_all_d**-.1818
pred.all_lasso_weights = predict(elastic_net, newx = new.xx, s=bestlam.weights,weights=weights.val)
resid_all_m1 <- numeric_cols_sing_rm$a1_all_rs-pred.all_lasso_weights**(-1/1.39)
res_all_m1 <- merge(resid_all_m1,all_years[,c('YEAR','DISTRICT')], all.x=TRUE, by='row.names')
res_all_m1_14_15 <- merge(res_all_m1[res_all_m1$YEAR==14,],res_all_m1[res_all_m1$YEAR==15,],by='DISTRICT')
plot(res_all_m1_14_15[,'1.x'], res_all_m1_14_15[,'1.y'])
cor(res_all_m1_14_15[,'1.x'], res_all_m1_14_15[,'1.y'],method='spearman')
res_all_m1_14_16 <- merge(res_all_m1[res_all_m1$YEAR==14,],res_all_m1[res_all_m1$YEAR==16,],by='DISTRICT')
plot(res_all_m1_14_16$x.x, res_all_m1_14_16$x.y)
cor(res_all_m1_14_16$x.x, res_all_m1_14_16$x.y,method='spearman')
res_all_m1_14_17 <- merge(res_all_m1[res_all_m1$YEAR==14,],res_all_m1[res_all_m1$YEAR==17,],by='DISTRICT')
plot(res_all_m1_14_17$x.x, res_all_m1_14_17$x.y)
cor(res_all_m1_14_17$x.x, res_all_m1_14_17$x.y,method='spearman')
```

Trying with weights first

## try all interactions
```{r}
X <- subset(frame_split$train ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y))
interaction.train <- model.matrix( ~.^2, data=X)
y <- frame_split$train$a1_all_rs**-1.39
#weights <- sqrt(frame_split$train$a1_all_d)
weights <- frame_split$train$a1_all_d**-.1818
#without weights
elastic_net.int <- cv.glmnet(interaction.train,y,nfolds = 10,weights = weights)
```

```{r}
summary(elastic_net.int)
plot(elastic_net.int)
coef(elastic_net.int, s='lambda.min')
```
##non-zero coefficients
```{r}
tmp_coeffs <- coef(elastic_net.int, s = "lambda.min")
data.frame(name = tmp_coeffs@Dimnames[[1]][tmp_coeffs@i + 1], coefficient = tmp_coeffs@x)
```

```{r}
bestlamint.weights =elastic_net.int$lambda.min
#pred.intlasso.train.weights <- predict(elastic_net, newx = X, s=bestlamint.weights, weights=weights)
```

```{r}
#X_test <- as.matrix(subset(frame_split$test ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
interaction.test <- model.matrix( ~.^2, data=subset(frame_split$test ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
weights.test <- sqrt(frame_split$test$a1_all_d)
#weights.test <- frame_split$test$a1_all_d**-.1818
#res.lasso <- predict(elastic_net,X_test,type ="coefficients",s=bestlam)
#res.lasso

pred.intlasso.test.weights = predict(elastic_net.int, newx = interaction.test, s=bestlamint.weights, weights=weights.test)
mean( (frame_split$test$a1_all_rs-pred.intlasso.test.weights**(-1/1.39))^2)
mean( abs(frame_split$test$a1_all_rs-pred.intlasso.test.weights**(-1/1.39)))

#new.xx <- as.matrix(subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
interaction.val <- model.matrix( ~.^2, data=subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
weights.val <- sqrt(frame_split$validate$a1_all_d)
#weights.val <- frame_split$validate$a1_all_d**-.1818
pred.intlasso.validate.weights = predict(elastic_net.int, newx = interaction.val, s=bestlamint.weights,weights=weights.val)
mean( (frame_split$validate$a1_all_rs-pred.intlasso.validate.weights**(-1/1.39))^2,na.rm = TRUE)
mean( abs(frame_split$validate$a1_all_rs-pred.intlasso.validate.weights**(-1/1.39)),na.rm = TRUE)
```

## test via correlation

### Random Forest
still need to tune the random forest
```{r}
library(randomForest)

X <- as.matrix(subset(frame_split$train,select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y)))

rf1 <- randomForest(frame_split$train$a1_all_rs~.,data=X, ntree=100)

```

```{r}
#sort(importance(rf1))

varImpPlot(rf1,n.var=20, main="Random Forest Variable Importance Plot")
```

#prediction with randomforest
Random forest performed slightly better than regression without hyperparameter tuning
Required 1000 trees
Roughly the same error with 100 trees
```{r}
new.xx <- as.matrix(subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y)))
pred6 = predict(rf1,new.xx)
mean( (frame_split$validate$a1_all_rs-pred6)^2)
mean( abs(frame_split$validate$a1_all_rs-pred6))
```

## random forest with all interactions?
```{r}
rf2 <- randomForest(y~.,data=X, ntree=100)
```

### XG Boost

```{r}
library(xgboost)

# need to select a grid of hyper parameters
X_train <- as.matrix(subset(frame_split$train,select=c(-k_indices,-train_ind,-a1_all_d,-a1_all_rs,-REGION.x,-REGION.y)))
y_train <- frame_split$train$a1_all_rs
X_test <- as.matrix(subset(frame_split$test,select=c(-k_indices,-train_ind,-a1_all_d,-a1_all_rs,-REGION.x,-REGION.y)))
y_test <- frame_split$test$a1_all_rs

params <- list(booster = "gblinear", objective = "reg:squarederror", eta=0.3, gamma=0, max_depth=70, min_child_weight=1, subsample=1, colsample_bytree=1)

dtrain <- xgb.DMatrix(X_train, label=y_train)
dtest <- xgb.DMatrix(X_test, label=y_test)

xgbcv <- xgb.cv( params = params, data = dtrain, nrounds = 500, nfold = 5, showsd = T, stratified = T, print_every_n = 20, early_stop_round = 20, maximize = F)
print(xgbcv)
```

```{r}
xgb1 <- xgb.train (params = params, data = dtrain, nrounds = 5000, watchlist = list(val=dtrain,train=dtest), print_every_n = 100, early_stop_round = 10, maximize = F , eval_metric = "error")
```

#view variable importance plot
```{r}
mat <- xgb.importance(feature_names=colnames(X_test), model=xgb1)
xgb.plot.importance(importance_matrix = mat[1:20],main='XGB Variable Importance Plot')

```

#predict with xgb 
XGB performed about as well as regression without much tuning
```{r}
new.xx <- as.matrix(subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_d,-a1_all_rs,-REGION.x,-REGION.y)))
pred7 = predict(xgb1,new.xx)
mean( (frame_split$validate$a1_all_rs-pred7)^2)
mean( abs(frame_split$validate$a1_all_rs-pred7))
```

#compare models on same validation set? 
Compare MSE on the test sets
and on the validation set
Also do MAE?
```{r}
  pred1=predict(model.no_weights.all_vars ,frame_split$validate)
  pred2=predict(model.weights.all_vars ,frame_split$validate)
  pred3=predict(m3.limited.weights ,frame_split$validate)
  pred4=predict(m4.noweights.limited ,frame_split$validate)
  pred.nsq=predict(m3.limited.weights.nsq ,frame_split$validate)
  new.xx <- as.matrix(subset(frame_split$validate ,select=c(-k_indices,-train_ind,-a1_all_rs,-a1_all_d,-REGION.x,-REGION.y)))
  pred5 = predict(elastic_net, newx = new.xx, s=bestlam)
  pred6 = predict(rf1,new.xx)
  pred7 = predict(xgb1,new.xx)
  mse.val <- rep(0,8)
  mae.val <- rep(0,8)
  model.names <- c('LM No Weights All Vars', 'LM Weights All Vars','LM Weights Limited Vars', 'LM No Weights Limited Vars', 'LM Weights Limited Vars No SQ','Lasso','Random Forest', 'XGBoost')
  mse.val[1] <- mean( (frame_split$validate$a1_all_rs-pred1**(-1/1.39))^2,na.rm = TRUE)
  mse.val[2] <- mean( (frame_split$validate$a1_all_rs-pred2**(-1/1.39))^2,na.rm = TRUE)
  mse.val[3] <- mean( (frame_split$validate$a1_all_rs-pred3**(-1/1.39))^2,na.rm = TRUE)
  mse.val[4] <- mean( (frame_split$validate$a1_all_rs-pred4**(-1/1.39))^2,na.rm = TRUE)
  mse.val[5] <- mean( (frame_split$validate$a1_all_rs-pred.nsq**(-1/1.39))^2,na.rm = TRUE)
  mse.val[6] <- mean( (frame_split$validate$a1_all_rs-pred5**(-1/1.39))^2)
  mse.val[7] <- mean( (frame_split$validate$a1_all_rs-pred6)^2,na.rm = TRUE)
  mse.val[8] <- mean( (frame_split$validate$a1_all_rs-pred7)^2)
  mse.val[9] <- mean( (frame_split$validate$a1_all_rs-pred.lasso.validate.weights**(-1/1.39))^2)
  mae.val[1] <- mean( abs(frame_split$validate$a1_all_rs-pred1**(-1/1.39)),na.rm = TRUE)
  mae.val[2] <- mean( abs(frame_split$validate$a1_all_rs-pred2**(-1/1.39)),na.rm = TRUE)
  mae.val[3] <- mean( abs(frame_split$validate$a1_all_rs-pred3**(-1/1.39)),na.rm = TRUE)
  mae.val[4] <- mean( abs(frame_split$validate$a1_all_rs-pred4**(-1/1.39)),na.rm = TRUE)
  mae.val[5] <- mean( abs(frame_split$validate$a1_all_rs-pred.nsq**(-1/1.39)),na.rm = TRUE)
  mae.val[6] <- mean( abs(frame_split$validate$a1_all_rs-pred5**(-1/1.39)),na.rm = TRUE)
  mae.val[7] <- mean( abs(frame_split$validate$a1_all_rs-pred6),na.rm = TRUE)
  mae.val[8] <- mean( abs(frame_split$validate$a1_all_rs-pred7))
  mae.val[9] <- mean( abs(frame_split$validate$a1_all_rs-pred.lasso.validate.weights))
  #test set
  pred1=predict(model.no_weights.all_vars ,frame_split$test)
  pred2=predict(model.weights.all_vars ,frame_split$test)
  pred3=predict(m3.limited.weights ,frame_split$test)
  pred4=predict(m4.noweights.limited ,frame_split$test)
  pred.nsq=predict(m3.limited.weights.nsq ,frame_split$test)
  new.xx <- as.matrix(subset(frame_split$test ,select=c(-k_indices,-train_ind,-a1_all_d,-a1_all_rs,-REGION.x,-REGION.y)))
  pred5 = predict(elastic_net, newx = new.xx, s=bestlam)
  pred6 = predict(rf1,new.xx)
  pred7 = predict(xgb1,new.xx)
  mse.test <- rep(0,8)
  mae.test <- rep(0,8)
  mse.test[1] <- mean( (frame_split$test$a1_all_rs-pred1**(-1/1.39))^2,na.rm = TRUE)
  mse.test[2] <- mean( (frame_split$test$a1_all_rs-pred2**(-1/1.39))^2,na.rm = TRUE)
  mse.test[3] <- mean( (frame_split$test$a1_all_rs-pred3**(-1/1.39))^2,na.rm = TRUE)
  mse.test[4] <- mean( (frame_split$test$a1_all_rs-pred4**(-1/1.39))^2,na.rm = TRUE)
  mse.test[5] <- mean( (frame_split$test$a1_all_rs-pred.nsq**(-1/1.39))^2,na.rm = TRUE)
  mse.test[6] <- mean( (frame_split$test$a1_all_rs-pred5**(-1/1.39))^2)
  mse.test[7] <- mean( (frame_split$test$a1_all_rs-pred6)^2,na.rm = TRUE)
  mse.test[8] <- mean( (frame_split$test$a1_all_rs-pred7)^2)
  mae.test[1] <- mean( abs(frame_split$test$a1_all_rs-pred1**(-1/1.39)),na.rm = TRUE)
  mae.test[2] <- mean( abs(frame_split$test$a1_all_rs-pred2**(-1/1.39)),na.rm = TRUE)
  mae.test[3] <- mean( abs(frame_split$test$a1_all_rs-pred3**(-1/1.39)),na.rm = TRUE)
  mae.test[4] <- mean( abs(frame_split$test$a1_all_rs-pred4**(-1/1.39)),na.rm = TRUE)
  mae.test[5] <- mean( abs(frame_split$test$a1_all_rs-pred.nsq**(-1/1.39)),na.rm = TRUE)
  mae.test[6] <- mean( abs(frame_split$test$a1_all_rs-pred5**(-1/1.39)),na.rm = TRUE)
  mae.test[7] <- mean( abs(frame_split$test$a1_all_rs-pred6),na.rm = TRUE)
  mae.test[8] <- mean( abs(frame_split$test$a1_all_rs-pred7))
  
  #compile
  final.comp <- data.frame(model.names,mse.val,mae.val,mse.test,mae.test)
  final.comp
```

#compute R-squared
```{r}
y_bar_val <- mean(frame_split$validate$a1_all_rs)
y_bar_test <- mean(frame_split$test$a1_all_rs)
r_s <- function(actual, pred, y_bar=y_bar_val){
  ss_tot <- sum((actual-y_bar)**2)
  ss_res <- sum((actual-pred)**2)
  ss_reg <- sum((pred-y_bar)**2)
  #return(1-ss_res/ss_tot)
  return(ss_reg/ss_tot)
}
#mse.val[3] <- mean( (frame_split$validate$a1_all_rs-pred3**(-1/1.39))^2,na.rm = TRUE)
r_s(frame_split$validate$a1_all_rs,pred3**(-1/1.39))
r_s(frame_split$test$a1_all_rs,pred3**(-1/1.39),y_bar=y_bar_test)
r_s(frame_split$validate$a1_all_rs,pred5**(-1/1.39))
r_s(frame_split$test$a1_all_rs,pred5**(-1/1.39),y_bar=y_bar_test)

```

#compare residuals vs fitted

#compare predicted vs acutal
```{r}
pred3.train=predict(m3.limited.weights ,frame_split$train)**(-1/1.39)
pred3.test=predict(m3.limited.weights ,frame_split$test)**(-1/1.39)
pred3.validate=predict(m3.limited.weights ,frame_split$validate)**(-1/1.39)
plot(frame_split$train$a1_all_rs,pred3.train)
plot(frame_split$test$a1_all_rs,pred3.test)
plot(frame_split$validate$a1_all_rs,pred3.validate)
plot(density(frame_split$train$a1_all_rs-pred3.train))
lines(density(frame_split$test$a1_all_rs-pred3.test),col=2)
lines(density(frame_split$validate$a1_all_rs-pred3.validate),col=3)
```

## compare mse

## time series remove correlation between schools
```{r}
set.seed(1011)
# break schools into 60/20/20

# pick schools from 2014
districts <- merge(numeric_cols_sing_rm,all_years$DISTRICT, all.x=TRUE, by='row.names')
head(districts[,c('YEAR','y')])
districts <- districts[order(districts$y,districts$YEAR),]
head(districts[,c('YEAR','y')])

# sort data by year and district

#not all districts have 4 years of data 
districts %>% group_by(districts$YEAR) %>% summarise(n= n())

#find districts with 4 years of data
dist_w_n <- districts %>% group_by(districts$y) %>% summarise(n= n())

#filter on districts with 4 years of data
dist4_years <- data.frame(dist_w_n[(dist_w_n$n ==4),])

#removed 170 year/schools for not having 4 years of data
districts4_years <- merge(districts, dist4_years, by.x = c('y'), by.y = c('districts.y'), all=FALSE)

#print result of fitler
districts4_years %>% group_by(districts4_years$YEAR) %>% summarise(n= n())

#split data into train and test 
dist_r_order <- sample(dist4_years$districts.y,size=nrow(dist4_years))

#split 60/20/20
districts4_years.train <- merge(districts, data.frame(y=dist_r_order[1:627]), by.x = c('y'), by.y = c('y'), all=FALSE)
districts4_years.test <- merge(districts, data.frame(y=dist_r_order[628:833]), by.x = c('y'), by.y = c('y'), all=FALSE)
districts4_years.val <- merge(districts, data.frame(y=dist_r_order[834:1041]), by.x = c('y'), by.y = c('y'), all=FALSE)

#add an intercept
#X.train <- as.matrix(cbind(intercept=rep(1,nrow(districts4_years.train)), #districts4_years.train[,c(m4.coef_names)]))
y.train <- districts4_years.train$a1_all_rs**(-1.39)
```

```{r}
#start_coef
#select_var.weight.limit.sq
beta.coef <- m4.coef
sigma_e <- var(m4.noweights.limited$residuals)
rho.start <- .6

param <- c( rho.start,sigma_e,beta.coef)
mle.1 <- function(param){
  rho <- param[1]
  s_e <- param[2]
  beta.coef <- param[3:length(param)]
  n <- nrow(X.train)
  cor_mat <- s_e*matrix(c(1,rho, rho**2, rho**3,
             rho,1, rho, rho**2,
             rho**2,rho, 1, rho,
             rho**3,rho**2, rho**1, 1),nrow=4)
  inv.cor_mat <- solve(cor_mat)
  S1 <- matrix(0, nrow=n,ncol=n)
  S2 <- matrix(0, nrow=n,ncol=n)
  for (i in seq(1,n, by=4)){
  S1[i:(i+3), i:(i+3)] <- cor_mat
  S2[i:(i+3), i:(i+3)] <- inv.cor_mat
  }
  -1*(-n*log(2*pi)-log(det(S1)+1)-1/2*t(y.train - X.train%*%beta.coef)%*%S2%*%(y.train - X.train%*%beta.coef))
}
ini=c( rho.start,sigma_e,beta.coef)
fit.mle1=nlm(mle.1, ini,print.level=1,stepmax=10, iterlim=100)




#construct convariance matrix
# make up a p based on the correlation I saw 
```
#fit models
consider removing sex male for multicolinearity, also it does not make sense as predictor
```{r}
X.train <- as.matrix(cbind(intercept=rep(1,nrow(districts4_years.train)), districts4_years.train[,c(m4.coef_names)]))
y.train <- districts4_years.train$a1_all_rs**(-1.39)

#cor(res_all_m1_14_15$x.x, res_all_m1_14_15$x.y,method='spearman')
#values I tried ; 0.7697, 0.6, 0.4
p <- 0.58
sig_e <- 1.798800e-09

cor_mat <- sig_e * matrix(c(1,       p-.3,    p**2,    p**3+.2,
                            p-.3,    1,       p-.2,    p**2+.1,
                            p**2,    p-.2,    1,       p,
                            p**3+.2,p**2+.1, p,    1),nrow=4)
inv_cor_mat <- solve(chol(cor_mat))
sigma_big <- matrix(0, nrow=nrow(X.train),ncol=nrow(X.train))
for (i in seq(1,nrow(X.train), by=4)){
sigma_big[i:(i+3), i:(i+3)] <- inv_cor_mat
}

# try without running log likelihood

y_star <- sigma_big%*%(y.train)
#districts4_years
x_star <- sigma_big%*%X.train[,-c(2,3,4,6,11,13)]
x_star1 <- sigma_big%*%X.train

lm_gls_kinda <- lm(y_star~x_star-1)
#summary(lm_gls_kinda)
#plot(lm_gls_kinda)
#m3.limited.weights.nsq$residuals

lm_gls_kinda.weights <- lm(y_star~x_star-1, weights = districts4_years.train$a1_all_d)
summary(lm_gls_kinda.weights)
plot(lm_gls_kinda.weights)
#m3.limited.weights.nsq$residuals

#predict()

years_res <- matrix(0, nrow(X.train)/4, 4)
for (i in seq(0,nrow(X.train)/4-1)){
  years_res[i,] <- lm_gls_kinda$residuals[(i*4+1):(i*4+4)]
}

cor(years_res)
```

#print outlier
```{r}
all_years['1119',c('DISTNAME','DNAME','DISTRICT')]
all_years[all_years$DISTRICT==4901,]
```

# Vif on predictors
```{r}
#cor(X_train)
#cor(x_star1)
cor(x_star)
#vif(lm_gls_kinda)
```

```{r}
years_res <- matrix(0, nrow(X.train)/4, 4)
for (i in seq(0,nrow(X.train)/4-1)){
  years_res[i,] <- lm_gls_kinda$residuals[(i*4+1):(i*4+4)]
}
#plot(years_res[,1],years_res[,2])
#cor(years_res[,1],years_res[,2])
#plot(years_res[,1],years_res[,3])
#cor(years_res[,1],years_res[,3])
#plot(years_res[,1],years_res[,4])
#cor(years_res[,1],years_res[,4])

cor(years_res)
years_res_df <- data.frame(years_res)
colnames(years_res_df) <- c('2014','2015','2016','2017')
plot(years_res_df)

```

#why are there 4 groups in the residuals?

#prediction vs actual


#test on training data
```{r}
X.test <- as.matrix(cbind(intercept=rep(1,nrow(districts4_years.test)), districts4_years.test[,c(m4.coef_names)]))
y.test <- districts4_years.test$a1_all_rs**(-1.39)

sigma_big.test <- matrix(0, nrow=nrow(X.test),ncol=nrow(X.test))
sigma_big.test.norm <- matrix(0, nrow=nrow(X.test),ncol=nrow(X.test))
#chol(cor_mat)
for (i in seq(1,nrow(X.test), by=4)){
sigma_big.test[i:(i+3), i:(i+3)] <- inv_cor_mat
sigma_big.test.norm[i:(i+3), i:(i+3)] <- chol(cor_mat)
}

# try without running log likelihood

y_star <- sigma_big.test%*%(y.test)
#districts4_years
x_star <- sigma_big.test%*%X.test[,-c(2,3,4,6,11,13)]

y_star.pred.test <- predict(lm_gls_kinda.weights,data.frame(x_star),weights=districts4_years.test$a1_all_d)

plot(y_star, y_star.pred.test)

y_pred_test_orig_scale <- (sigma_big.test.norm %*% y_star.pred.test)**(-1/1.39)
plot(districts4_years.test$a1_all_rs, y_pred_test_orig_scale)

#test R-squared

```
#test on validation data
```{r}
X.val <- as.matrix(cbind(intercept=rep(1,nrow(districts4_years.val)), districts4_years.val[,c(m4.coef_names)]))
y.val <- districts4_years.val$a1_all_rs**(-1.39)

sigma_big.val <- matrix(0, nrow=nrow(X.val),ncol=nrow(X.val))
sigma_big.val.norm <- matrix(0, nrow=nrow(X.val),ncol=nrow(X.val))
#chol(cor_mat)
for (i in seq(1,nrow(X.val), by=4)){
sigma_big.val[i:(i+3), i:(i+3)] <- inv_cor_mat
sigma_big.val.norm[i:(i+3), i:(i+3)] <- chol(cor_mat)
}

# try without running log likelihood

y_star <- sigma_big.val%*%(y.val)
#districts4_years
x_star <- sigma_big.val%*%X.val[,-c(2,3,4,6,11,13)]

y_star.pred.val <- predict(lm_gls_kinda.weights,data.frame(x_star),weights=districts4_years.val$a1_all_d)

plot(y_star, y_star.pred.val)

y_pred_val_orig_scale <- (sigma_big.val.norm %*% y_star.pred.val)**(-1/1.39)
plot(districts4_years.val$a1_all_rs, y_pred_val_orig_scale)

#test R-squared
```

#MLE with only 2 variables year and prior math score, but more parameters in the variance
```{r}
X.train <- as.matrix(cbind(intercept=rep(1,nrow(districts4_years.train)), districts4_years.train[,c('m_all_rs')]))
y.train <- districts4_years.train$a1_all_rs**(-1.39)

pre_model <- lm(y.train~X.train-1)


beta.coef <- coef(pre_model)
sigma_e <- var(pre_model$residuals)
rho.start <- .6

param <- c(.28, .34,.39,.38,.43, .58,sigma_e,beta.coef)
mle.1 <- function(param){
  p_12 <- param[1]
  p_13 <- param[2]
  p_14 <- param[3]
  p_23 <- param[4]
  p_24 <- param[5]
  p_34 <- param[6]
  #rho <- param[1]
  s_e <- param[7]
  beta.coef <- param[8:length(param)]
  n <- nrow(X.train)
  cor_mat <- s_e*matrix(c(1,p_12, p_13, p_14,
                        p_12,1, p_23, p_24,
                        p_13,p_23, 1, p_34,
                        p_14,p_24, p_34, 1),nrow=4)
  inv.cor_mat <- solve(cor_mat)
  S1 <- matrix(0, nrow=n,ncol=n)
  S2 <- matrix(0, nrow=n,ncol=n)
  for (i in seq(1,n, by=4)){
  S1[i:(i+3), i:(i+3)] <- cor_mat
  S2[i:(i+3), i:(i+3)] <- inv.cor_mat
  }
  -1*(-n*log(2*pi)-log(det(S1))-1/2*t(y.train - X.train%*%beta.coef)%*%S2%*%(y.train - X.train%*%beta.coef))
}
ini=c( .28, .34,.39,.38,.43, .58,sigma_e,beta.coef)
ini=c()
fit.mle1=nlm(mle.1, ini,print.level=1,stepmax=10, iterlim=100)
```
#lasso with the transformed regression ? 
```{r}
X.train <- as.matrix(districts4_years.train[,c(6, 7,8,11:112)])
y.train <- districts4_years.train$a1_all_rs**(-1.39)

p <- 0.58
sig_e <- 1.798800e-09

cor_mat <- sig_e * matrix(c(1,       p-.3,    p**2,    p**3+.2,
                            p-.3,    1,       p-.2,    p**2+.1,
                            p**2,    p-.2,    1,       p,
                            p**3+.2,p**2+.1, p,    1),nrow=4)
inv_cor_mat <- solve(chol(cor_mat))
sigma_big <- matrix(0, nrow=nrow(X.train),ncol=nrow(X.train))
sigma_big_norm <- matrix(0, nrow=nrow(X.train),ncol=nrow(X.train))
for (i in seq(1,nrow(X.train), by=4)){
sigma_big[i:(i+3), i:(i+3)] <- inv_cor_mat
sigma_big_norm[i:(i+3), i:(i+3)] <- chol(cor_mat)
}

# try without running log likelihood

y_star <- sigma_big%*%(y.train)
#districts4_years
#x_star <- sigma_big%*%X.train[,-c(2,3,4,6,11,13)]
x_star <- sigma_big%*%X.train
```
```{r}
data.frame(matrix(c(1,       p-.3,    p**2,    p**3+.2,
                            p-.3,    1,       p-.2,    p**2+.1,
                            p**2,    p-.2,    1,       p,
                            p**3+.2,p**2+.1, p,    1),nrow=4))
```

## select model with BIC
```{r}
X.train <- as.matrix(districts4_years.train[,c(6, 7,8,11:112)])
y.train <- districts4_years.train$a1_all_rs**(-1.39)
y_star <- sigma_big%*%(y.train)
x_star <- data.frame(sigma_big%*%X.train)
regfit.full =regsubsets(y_star∼.,data=x_star,nvmax =70,method=c('seqrep'),weights=districts4_years.train$a1_all_d)
reg.summary=(summary(regfit.full))
plot(reg.summary$bic ,xlab =" Number of Variables ",
     ylab=" BIC",type="l",main='Number of Variables in Model by BIC')
abline(v=40,col='red')
text(40,-12000,paste('Miniumum BIC:',round(reg.summary$bic[which.min(reg.summary$bic)],digits=2)))
which.min(reg.summary$bic)
reg.summary$bic[which.min(reg.summary$bic)]
```

#subset variables removed
Seq - 11910
Forward - 11888, 11878
```{r}
X.train <- as.matrix(districts4_years.train[,c(6, 7,8,11:112)])
y.train <- districts4_years.train$a1_all_rs**(-1.39)
y_star <- sigma_big%*%(y.train)
x_star <- subset(data.frame(sigma_big%*%X.train),select=c(-m_all_rs,-w_all_rs,-r_all_rs,-DPSTTOFC,
-DPSTTOFP,-DPSXTOFP,-DPSSTOSA,-DPSUTOSA,-DPSAMIFP,-DPFEAOPFK,-DPFEAINST,-a1_sexm_d_pct,
-a1_sexf_d_pct,-a1_lepc_d_pct,-a1_lepf_d_pct,-DPFRASTAP,-DPFRAALLK,
-DZRVLOCP,-DPSATOFC,-DPSCTOSA,-DPFRAALLT,-a1_lep0_d_pct,-DPSTEXPA,-DPFTADPR,
-a1_leps_d_pct,-DPFPAREGP,-DPSTREFP,-DPSAKIDR,-a1_ti10_d_pct,-a1_ti16_d_pct
,-DPSTTOSA,-DPSTKIDR,-DPSTHIFP,-DPSTWHFP,-DPFEAALLT,-DPFEAOPFT,-DPFEAINSP,-DZEXADSP,-DZEXPLAP,-DZEXOTHP,-DPFEAINSK,-TAXRATENUM,-a1_eco1_d_pct))
regfit.full =regsubsets(y_star∼.,data=x_star,nvmax =70,method=c('seqrep'),weights=districts4_years.train$a1_all_d)
reg.summary=(summary(regfit.full))
plot(reg.summary$bic ,xlab =" Number of Variables ",
     ylab=" BIC",type="l",main='Number of Variables in Model by BIC')
abline(v=which.min(reg.summary$bic),col='red')
text(which.min(reg.summary$bic),-10000,paste('Miniumum BIC:',round(reg.summary$bic[which.min(reg.summary$bic)],digits=2)))
which.min(reg.summary$bic)
reg.summary$bic[which.min(reg.summary$bic)]
```

```{r}
#plot(regfit.full)
#coef(regfit.full,41)
#select_var
gls.bic <- lm(y_star ~ .,data=x_star[,c(names(coef(regfit.full,40))[-1])],weights=districts4_years.train$a1_all_d)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
summary(gls.bic )
plot(gls.bic)
```

##run best linear model 
```{r}
gls.bic2 <- lm(y_star ~ .,data=x_star[,c(names(coef(regfit.full,40))[-c(1,2,3,5,6,9,10,13,14,15,17:20,26,30)])],weights=districts4_years.train$a1_all_d)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
summary(gls.bic2)
plot(gls.bic2)
```

#run with just old math scores
```{r}
X_math <- data.frame(m_all_rs=sigma_big%*%X.train[,'m_all_rs'])
gls.bic4 <- lm(y_star ~ .,data=X_math,weights=districts4_years.train$a1_all_d)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
summary(gls.bic4)
plot(gls.bic4)
data.frame(vif(gls.bic4))
```

##run best linear model 
```{r}
sel_nm <- c('DPSUTOFP','DPSTURNR','DPSTBLFP','DPSTO2FP','DPFRAFEDP','DPFUNAB1T','DPFUNA4T','DPFPACOMP','DPFPABILP','DPFPREKP','DPFPAOTHP','a1_ethh_d_pct','a1_ethi_d_pct','a1_etha_d_pct','a1_ethb_d_pct','a1_ethw_d_pct','a1_eth2_d_pct','a1_eco2_d_pct','a1_ti17_d_pct','a1_migy_d_pct','a1_bil2_d_pct','a1_esl2_d_pct','a1_esl3_d_pct','a1_gify_d_pct','a1_atry_d_pct','a1_voc2_d_pct')
#gls.bic3 <- lm(y_star ~ .,data=x_star[,c(names(coef(regfit.full,26))[-1])],weights=districts4_years.train$a1_all_d)
gls.bic3 <- lm(y_star ~ .,data=x_star[,sel_nm],weights=districts4_years.train$a1_all_d)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
summary(gls.bic3)
plot(gls.bic3)
data.frame(vif(gls.bic3))
```

#check for correlation among predictors
```{r}
data.frame(vif(gls.bic))
```

```{r}
data.frame(vif(gls.bic2))
```

```{r}
data.frame(vif(gls.bic3))
```

## marginal model plots
```{r}
for (nm in names(coef(gls.bic3))[-1]){
  plot(x_star[,nm],gls.bic3$residuals,xlab=nm)
}
```

#check correlations
```{r}
years_res <- matrix(0, nrow(X.train)/4, 4)
for (i in seq(0,nrow(X.train)/4-1)){
  years_res[i,] <- gls.bic3$residuals[(i*4+1):(i*4+4)]
}
cor(years_res_df)
colnames(years_res_df) <- c('2014','2015','2016','2017')
plot(years_res_df)
```

#transform coefficients back
```{r}
coef(gls.bic3)
-1*sign(coef(gls.bic3))*abs(coef(gls.bic3))**(-1/1.39)
```

#plot predictions
```{r}
y_star.train <- sigma_big%*%(y.train)
y_star.pred.train<-(sigma_big_norm %*% gls.bic3$fitted.values)**(-1/1.39)
y_star.pred.train_math<-(sigma_big_norm %*% gls.bic4$fitted.values)**(-1/1.39)

#X.train <- as.matrix(districts4_years.train[,c(6, 7,8,11:112)])
#y.train <- districts4_years.train$a1_all_rs**(-1.39)


X.test <- as.matrix(districts4_years.test[,c(6, 7,8,11:112)])
y.test <- districts4_years.test$a1_all_rs**(-1.39)

sigma_big.test <- matrix(0, nrow=nrow(X.test),ncol=nrow(X.test))
sigma_big.test.norm <- matrix(0, nrow=nrow(X.test),ncol=nrow(X.test))
#chol(cor_mat)
for (i in seq(1,nrow(X.test), by=4)){
sigma_big.test[i:(i+3), i:(i+3)] <- inv_cor_mat
sigma_big.test.norm[i:(i+3), i:(i+3)] <- chol(cor_mat)
}

# try without running log likelihood

y_star.test <- sigma_big.test%*%(y.test)
#districts4_years
x_star <- sigma_big.test%*%X.test[,-c(2,3,4,6,11,13)]

y_star.pred.test <- predict(gls.bic3,data.frame(x_star),weights=districts4_years.test$a1_all_d)
y_star.pred.test_math <- predict(gls.bic4,data.frame(x_star),weights=districts4_years.test$a1_all_d)

y_pred_test_orig_scale <- (sigma_big.test.norm %*% y_star.pred.test)**(-1/1.39)
y_pred_test_orig_scale_math <- (sigma_big.test.norm %*% y_star.pred.test_math)**(-1/1.39)

X.val <- as.matrix(districts4_years.val[,c(6, 7,8,11:112)])
y.val <- districts4_years.val$a1_all_rs**(-1.39)

sigma_big.val <- matrix(0, nrow=nrow(X.val),ncol=nrow(X.val))
sigma_big.val.norm <- matrix(0, nrow=nrow(X.val),ncol=nrow(X.val))
#chol(cor_mat)
for (i in seq(1,nrow(X.val), by=4)){
sigma_big.val[i:(i+3), i:(i+3)] <- inv_cor_mat
sigma_big.val.norm[i:(i+3), i:(i+3)] <- chol(cor_mat)
}

# try without running log likelihood

y_star.val <- sigma_big.val%*%(y.val)
#districts4_years
x_star <- sigma_big.val%*%X.val[,-c(2,3,4,6,11,13)]

y_star.pred.val <- predict(gls.bic3,data.frame(x_star),weights=districts4_years.val$a1_all_d)
y_pred_val_orig_scale <- (sigma_big.val.norm %*% y_star.pred.val)**(-1/1.39)

y_star.pred.val_math <- predict(gls.bic4,data.frame(x_star),weights=districts4_years.val$a1_all_d)
y_pred_val_orig_scale_math <- (sigma_big.val.norm %*% y_star.pred.val_math)**(-1/1.39)



plot(y_star.train,gls.bic3$fitted.values, main='Train Predicted',xlab='Actual Transformed Scale',ylab='Predicted Transformed Scale')
plot(districts4_years.train$a1_all_rs,y_star.pred.train, main='Train Original Scale',xlab='Actual Original Scale',ylab='Predicted Original Scale')

plot(y_star.test, y_star.pred.test, main='Test Predicted',xlab='Actual Transformed Scale',ylab='Predicted Transformed Scale')
plot(districts4_years.test$a1_all_rs, y_pred_test_orig_scale, main='Test Original Scale',xlab='Actual Original Scale',ylab='Predicted Original Scale')

plot(y_star.val, y_star.pred.val, main='Validation Predicted',xlab='Actual Transformed Scale',ylab='Predicted Transformed Scale')
plot(districts4_years.val$a1_all_rs, y_pred_val_orig_scale, main='Validation Original Scale',xlab='Actual Original Scale',ylab='Predicted Original Scale')
```

## Outliers
```{r}
which((y_star.pred.train-districts4_years.train$a1_all_rs)==max(y_star.pred.train-districts4_years.train$a1_all_rs))
districts4_years.test[458,c('YEAR','Row.names')]
all_years['4972',c('YEAR','DISTNAME','a1_all_d',sel_nm)]
which((y_pred_test_orig_scale-districts4_years.test$a1_all_rs)==max(y_pred_test_orig_scale-districts4_years.test$a1_all_rs))
districts4_years.train[183,c('YEAR','Row.names')]
write.csv(all_years['3387',c('YEAR','DISTNAME','a1_all_d',sel_nm)],"E:/STAT685/train_outlier.csv")
```

## Errors
In original or different scale?
```{r}
#in original scale
sqrt(mean((districts4_years.train$a1_all_rs-y_star.pred.train)**2))
mean(abs(districts4_years.train$a1_all_rs-y_star.pred.train))
sqrt(mean((districts4_years.test$a1_all_rs - y_pred_test_orig_scale)**2))
mean(abs(districts4_years.test$a1_all_rs - y_pred_test_orig_scale))
sqrt(mean((districts4_years.val$a1_all_rs- y_pred_val_orig_scale)**2))
mean(abs(districts4_years.val$a1_all_rs- y_pred_val_orig_scale))
```

##For just math
```{r}
sqrt(mean((districts4_years.train$a1_all_rs-y_star.pred.train_math)**2))
mean(abs(districts4_years.train$a1_all_rs-y_star.pred.train_math))
sqrt(mean((districts4_years.test$a1_all_rs - y_pred_test_orig_scale_math)**2))
mean(abs(districts4_years.test$a1_all_rs - y_pred_test_orig_scale_math))
sqrt(mean((districts4_years.val$a1_all_rs- y_pred_val_orig_scale_math)**2))
mean(abs(districts4_years.val$a1_all_rs- y_pred_val_orig_scale_math))
```

Removed Extra econ variables for high vif
trying with sqrt weights
```{r}
#sub_model_build <- subset(frame_split$test,select=c(-k_indices,-train_ind,-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPSATOFC,-DPSTTOFC,-DPSCTOFP,-DPSSTOFP,-DPSUTOFP,-DPSTTOFP,-DPSETOFP,-DPSXTOFP,-DPSAMIFP,-DPSAKIDR,-DPSTKIDR,-DPST05FP,-DPSTEXPA,-DPSTBLFP,-DPSTHIFP,-DPSTWHFP,-DPSTO2FP,-DPSTREFP,-DPSTSPFP,-DPSTCOFP,-DPSTBIFP,-DPSTVOFP,-DPSTGOFP,-DPFRAALLT,-DPFRASTAP,-DZRVLOCP,-DPFRAFEDP,-DPFEAALLT, -DPFEAINST))
sub_model_build <- subset(frame_split$train,select=c(-a1_all_d,-REGION.x,-REGION.y,-r_all_rs,-w_all_rs,-DPFEAALLT,-DPFEAOPFT,-DPFRAALLT,-DPSTTOFC,-DPFEAINST))
weights <- frame_split$train[,c("a1_all_d")]
reg.best=regsubsets (a1_all_rs**-1.39∼.,data=sub_model_build , nvmax =70,method=c('forward'),weights=weights)
coef(reg.best,20)
start_coef.weight.limit <- coef(reg.best,20)
select_var.weight.limit <- names(coef(reg.best,20))[-1]
```

```{r}
#select_var
m3.limited.weights.nsq <- lm(a1_all_rs**-1.39 ~ .
             ,data=sub_model_build[,c(select_var.weight.limit,'a1_all_rs')],weights=weights)
#m_no_weights <- lm(a1_all_rs~.,data=sub_model_no_weights)
summary(m3.limited.weights.nsq)
```

#scratch
```{r}
all_years[all_years$DNAME=='DALLAS ISD',c('YEAR','DNAME','a1_all_rs')]
```
